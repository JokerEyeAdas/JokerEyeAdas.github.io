<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>进阶|HDR-ISP支持ROS2以及GPU实时处理啦！</title>
    <link href="/2023/10/28/12.HDR-ISP%E6%94%AF%E6%8C%81ROS2%E4%BB%A5%E5%8F%8AGPU%E5%95%A6/"/>
    <url>/2023/10/28/12.HDR-ISP%E6%94%AF%E6%8C%81ROS2%E4%BB%A5%E5%8F%8AGPU%E5%95%A6/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>之前我们开源了一份HDR-ISP代码供大家入门学习，但很多后台同学反馈CPU版本是实时性不够、对于相机无法实时处理。没关系，今天Cuda加速、支持ROS2可以实时处理的的HDR-ISP GPU版本来啦！</p><p><strong>此次GPU版本开源版本只提供lib供学习测试！加入星球后可以找星主获取资料以及源码，白嫖党、伸手党可以自行走开！</strong></p><h1 id="1-项目描述"><a href="#1-项目描述" class="headerlink" title="1. 项目描述"></a>1. 项目描述</h1><h2 id="1-1-项目特点"><a href="#1-1-项目特点" class="headerlink" title="1.1 项目特点"></a>1.1 项目特点</h2><p><strong>一个使用C++编写的、使用GPU加速用于HDR相机的ISP Pipeline</strong></p><ul><li>ISP模块使用C风格编写</li><li>除仓库文件外，无其它第三方库依赖</li><li>可以通过json配置自定义你的pipeline</li><li><del>可以在任意支持C++的嵌入式平台上部署</del></li><li><strong>可以在支持Cuda的PC上运行，同时支持Nvidia Jeston嵌入式设备</strong></li><li><strong>支持文件离线处理、支持ROS2实时Online运行</strong></li><li><strong>支持通过配置选择ISP Pipeline是在CPU上运行还是GPU上运行</strong></li></ul><h2 id="1-2-默认Pipeline"><a href="#1-2-默认Pipeline" class="headerlink" title="1.2 默认Pipeline"></a>1.2 默认Pipeline</h2><p><strong>默认Json配置pipeline:</strong></p><p><img src="/img/6_HDR_ISP/pipeline.png" alt="Pipeline"></p><h2 id="1-3-当前支持的模块"><a href="#1-3-当前支持的模块" class="headerlink" title="1.3 当前支持的模块"></a>1.3 当前支持的模块</h2><p><strong>支持的ISP模块列表(CPU and GPU)：</strong></p><ul><li>Raw Domain<ul><li><input checked="" disabled="" type="checkbox"> MipiUnPack: Mipi原始数据转RAW16</li><li><input checked="" disabled="" type="checkbox"> DePwl: 解压缩数据</li><li><input checked="" disabled="" type="checkbox"> Dpc: 动态坏点校准</li><li><input checked="" disabled="" type="checkbox"> Lsc: 镜头阴影校准</li><li><input checked="" disabled="" type="checkbox"> Blc: 黑电平校准</li><li><input disabled="" type="checkbox"> Rns: Raw域降噪</li><li><input checked="" disabled="" type="checkbox"> WbGain: 白平衡增益</li><li><input checked="" disabled="" type="checkbox"> Demoasic: 解马赛克</li></ul></li><li>RGB Domain<ul><li><input checked="" disabled="" type="checkbox"> Ltm: 局部色调映射</li><li><input checked="" disabled="" type="checkbox"> RgbGamma: rgb伽马曲线</li><li><input checked="" disabled="" type="checkbox"> Ccm: 色彩校准矩阵</li><li><input checked="" disabled="" type="checkbox"> Rgb2Yuv: rgb域转yuv域</li></ul></li><li>YUV Domain<ul><li><input checked="" disabled="" type="checkbox"> YGamma: 灰度伽马曲线</li><li><input checked="" disabled="" type="checkbox"> Contrast: 对比度提升</li><li><input checked="" disabled="" type="checkbox"> Sharpen: 锐化边缘增强</li><li><input checked="" disabled="" type="checkbox"> Cns: 颜色滤波</li><li><input checked="" disabled="" type="checkbox"> Saturation: 色度提升</li><li><input checked="" disabled="" type="checkbox"> Yuv2Rgb: yuv域rgb域</li></ul></li></ul><h1 id="2-如何编译与运行"><a href="#2-如何编译与运行" class="headerlink" title="2. 如何编译与运行"></a>2. 如何编译与运行</h1><h2 id="2-1-Linux系统"><a href="#2-1-Linux系统" class="headerlink" title="2.1 Linux系统"></a>2.1 Linux系统</h2><p><strong>开发环境 :</strong> </p><ul><li>nvcc</li><li>cmake</li><li>g++</li></ul><p><strong>编译</strong></p><ul><li><strong>不使用ROS2</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/JokerEyeAdas/HDR-ISP<br><span class="hljs-built_in">cd</span> HDR-ISP/<br>git checkout gpu_dev<br><span class="hljs-built_in">mkdir</span> build<br>cmake ..<br>make -j12<br></code></pre></td></tr></table></figure><ul><li><strong>使用ROS2编译</strong></li></ul><ol><li>克隆仓库</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/JokerEyeAdas/HDR-ISP<br><span class="hljs-built_in">cd</span> HDR-ISP/<br>git checkout gpu_dev<br></code></pre></td></tr></table></figure><ol><li>编辑 CMakeLists.txt，设置ROS2_ENABLE成true</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs CMakeLists.txt">set(ROS2_ENABLE true)<br></code></pre></td></tr></table></figure><ol start="3"><li>编译</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> <span class="hljs-variable">$&#123;ros2_wk&#125;</span><br>colcon build<br></code></pre></td></tr></table></figure><h2 id="2-2-Windows"><a href="#2-2-Windows" class="headerlink" title="2.2 Windows"></a>2.2 Windows</h2><p><strong>开发环境 (x64):</strong> </p><ul><li>vs code</li><li>cmake</li><li>nvcc</li><li>vs2019 c++ gen tool</li></ul><p><img src="/img/6_HDR_ISP/compile.png" alt="build tool"> </p><p><strong>编译</strong></p><ul><li><strong>不使用 ROS2</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/JokerEyeAdas/HDR-ISP<br>code HDR-ISP<br>git checkout gpu_dev<br><span class="hljs-comment">#cmake choose Debug or Release</span><br><span class="hljs-comment">#compiler choose xxx-amd64</span><br><span class="hljs-comment">#build all</span><br></code></pre></td></tr></table></figure><ul><li><strong>使用ROS2</strong></li></ul><ol><li>克隆仓库</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/JokerEyeAdas/HDR-ISP<br><span class="hljs-built_in">cd</span> HDR-ISP/<br>git checkout gpu_dev<br></code></pre></td></tr></table></figure><ol start="2"><li>编辑CMakeLists.txt设置ROS2_ENABLE为true</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs CMakeLists.txt">set(ROS2_ENABLE true)<br></code></pre></td></tr></table></figure><ol start="3"><li>编译</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> <span class="hljs-variable">$&#123;ros2_wk&#125;</span><br>colcon build --merge-install<br></code></pre></td></tr></table></figure><h2 id="2-3-运行"><a href="#2-3-运行" class="headerlink" title="2.3 运行"></a>2.3 运行</h2><ul><li>离线模式</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> build<br><span class="hljs-comment">#cp cfgs and data</span><br><span class="hljs-built_in">cp</span> -r ../data/ ./<br><span class="hljs-built_in">cp</span> -r ../cfgs/ ./<br><span class="hljs-comment">#run isp</span><br>./HDR_ISP ./cfgs/isp_config_cannon.json<br></code></pre></td></tr></table></figure><ul><li>在线模式</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">ros2 run hdr_isp pub_raw ./cfgs/xxxx.json<br>ros2 run hdr_isp hdr_isp ./cfgs/xxxx.json<br>ros2 run rviz2 rviz2<br></code></pre></td></tr></table></figure><h2 id="2-4-改变模式以及运行设备"><a href="#2-4-改变模式以及运行设备" class="headerlink" title="2.4 改变模式以及运行设备"></a>2.4 改变模式以及运行设备</h2><ul><li>使用GPU加速（通过Json进行配置）:</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;device&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;gpu&quot;</span><span class="hljs-punctuation">,</span><br></code></pre></td></tr></table></figure><ul><li>使用CPU运行（通过Json进行配置）:</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;device&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;cpu&quot;</span><span class="hljs-punctuation">,</span><br></code></pre></td></tr></table></figure><ul><li>ROS2实时处理模式以及修改Topic</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;mode&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;online&quot;</span><span class="hljs-punctuation">,</span><br><span class="hljs-attr">&quot;topic&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;/raw/connan&quot;</span><span class="hljs-punctuation">,</span><br></code></pre></td></tr></table></figure><ul><li>离线处理RAW图</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;mode&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;offline&quot;</span><span class="hljs-punctuation">,</span><br><span class="hljs-attr">&quot;raw_file&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;./data/connan_raw14.raw&quot;</span><span class="hljs-punctuation">,</span><br><span class="hljs-attr">&quot;out_file_path&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;./&quot;</span><span class="hljs-punctuation">,</span><br></code></pre></td></tr></table></figure><h2 id="2-5-如何调试参数"><a href="#2-5-如何调试参数" class="headerlink" title="2.5 如何调试参数"></a>2.5 如何调试参数</h2><p><strong>通过修改json配置来配置ISP模块的基本参数</strong></p><p>如，修改sensor基本参数：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;info&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;sensor_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;cannon&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;cfa&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;RGGB&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;data_type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;RAW16&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;bpp&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">16</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;max_bit&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">14</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;width&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">6080</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;height&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4044</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;mipi_packed&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><br><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br></code></pre></td></tr></table></figure><p>修改rgb gamma参数如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;rgbgamma&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;enable&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;in_bit&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">10</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;out_bit&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">8</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;gammalut_nums&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">11</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;gammalut&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.3504950718773984</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.48243595264750255</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.57750428843709</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.6596458942714417</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.731034378464739</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.7925580792857235</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.8509817015104557</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.9029435754464383</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.9534255851019492</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">1.0</span><br>        <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h1 id="3-GPU性能与ROS2支持"><a href="#3-GPU性能与ROS2支持" class="headerlink" title="3. GPU性能与ROS2支持"></a>3. GPU性能与ROS2支持</h1><p><strong>使用ROS以及GPU</strong></p><ul><li>GPU性能(不发布ISP处理结果)</li></ul><table><thead><tr><th>Index</th><th>Resolution</th><th>GTX1080</th><th>MX550</th></tr></thead><tbody><tr><td>1</td><td>6080*4044</td><td>15</td><td>8</td></tr><tr><td>2</td><td>3840*2160</td><td>40</td><td>20</td></tr><tr><td>3</td><td>1920*1080</td><td>125</td><td>60</td></tr></tbody></table><ul><li>ROS2 Online mode</li></ul><p><img src="/img/6_HDR_ISP/ros2_online.png" alt="ROS2"></p><h1 id="4-后续工作"><a href="#4-后续工作" class="headerlink" title="4. 后续工作"></a>4. 后续工作</h1><h2 id="4-1-TBD工作"><a href="#4-1-TBD工作" class="headerlink" title="4.1 TBD工作"></a>4.1 TBD工作</h2><ul><li>编写Python或者GUI调试工具</li></ul><h2 id="4-2-资料获取"><a href="#4-2-资料获取" class="headerlink" title="4.2 资料获取"></a>4.2 资料获取</h2><ul><li>如果想学习源码、获取模块说明，请加入星球，我们共同开发！（毕竟开发者也要恰饭）</li></ul><p><img src="/img/6_HDR_ISP/knowledge.png" alt="knowledge"></p><ul><li>加入星球:</li></ul><p><img src="/img/6_HDR_ISP/xingqiu.jpg" alt="知识星球"></p><h2 id="4-3-项目支持"><a href="#4-3-项目支持" class="headerlink" title="4.3 项目支持"></a>4.3 项目支持</h2><ul><li>感谢您的支持，希望我的项目对您有帮助~</li></ul><p><img src="/img/6_HDR_ISP/AppreciationCode.png" alt="Appreciation Code"></p><h1 id="5-结束语"><a href="#5-结束语" class="headerlink" title="5. 结束语"></a>5. 结束语</h1><p>今天我们给大家介绍了HDR-ISP-GPU，希望对于入门的新人有一定的借鉴作用，同时希望我们的开源对于处于行业里面的你们有所帮助！</p><p>如果您对自动驾驶感兴趣，可以关注本公众号，当然有想了解的话题，也可以私信我，我们将对各位看官感兴趣的话题进行技术分享。</p><p>项目地址：<a href="https://github.com/JokerEyeAdas/HDR-ISP">https://github.com/JokerEyeAdas/HDR-ISP</a></p><p>项目分支：gpu_dev</p><p>项目GitHub快速传送门：<a href="https://github.com/JokerEyeAdas/HDR-ISP">HDR-ISP</a></p><h1 id="6-项目预告"><a href="#6-项目预告" class="headerlink" title="6. 项目预告"></a>6. 项目预告</h1><p>哈哈，还没完！后台有老哥想要3D AVM实现方法，没关系，现在已经在准备实现中了，目前3D碗以及车的模型已经导入，状态如下：</p><p><img src="/img/6_HDR_ISP/3d_avm.png" alt="3D AVM"></p><p>想学习的加入知识星球，第一时间获取资料，今天就到这，peace。</p><hr><p><strong>如果您对ADAS感兴趣，欢迎关注我的公众号、知乎、CSDN等，同时发表文章中使用源码会在我的GitHub进行开源（网页About Me中有公众号、Github等信息）</strong></p>]]></content>
    
    
    <categories>
      
      <category>ISP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HDR</tag>
      
      <tag>ISP</tag>
      
      <tag>GPU</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CIS|豪威200MP移动设备图像传感器技术论文解析</title>
    <link href="/2023/10/07/11.Ovt%E7%A7%BB%E5%8A%A8%E8%AE%BE%E5%A4%87200Mp%E5%9B%BE%E5%83%8F%E4%BC%A0%E6%84%9F%E5%99%A8/"/>
    <url>/2023/10/07/11.Ovt%E7%A7%BB%E5%8A%A8%E8%AE%BE%E5%A4%87200Mp%E5%9B%BE%E5%83%8F%E4%BC%A0%E6%84%9F%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>在之前的文章中，我们介绍了索尼、安森美以及三星等Sensor厂家在车载领域中的技术论文，分析了各个厂家不同的技术路线、Sensor架构以及差异点。今天，笔者借豪威科技在移动端200Mega Pixels产品的技术论文，讲解消费级CIS传感器的基本架构、工艺以及与车载应用不同之处。</p><p>本项工作开发了一种新的40&#x2F;22nm堆叠式、像素尺寸为0.61µm、200兆像素CMOS图像传感器（CIS）。通过使用22nm逻辑晶圆工艺节点代替40nm完成数字逻辑部分，在保持相同时钟频率的同时，数字功耗降低了一半，同时全高清（FHD）帧速率从240fps提高到480fps。在这项工作中，我们展示了一种新的源极跟随器（SF）晶体管架构，与我们以前的0.7µm像素相比，SF跨导（Gm）高出63%。实现了5.0ke-的全阱容量（FWC），与0.7µm像素相比，具有更好的白像素（WP）性能。我们展示了0.61µm四元光电二极管（QPD）结构，该结构能够在可见光范围内实现与0.7µm QPD相当的量子效率（QE）性能。</p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>手机行业领域发展迅速，由于各个手机厂商着重于提高多摄像头移动设备的图像质量，因此对高分辨率和小像素间距图像传感器的需求一直在稳步增加。尽管像素间距缩放低于可见光衍射极限，但由于图像信号处理的逐步改进，仍能继续实现更好的图像质量。</p><p>高分辨率图像传感器需要更低的功耗和更快的读出速度，因为传感器必须同时管理大量像素。晶片堆叠工艺应用于高分辨率CIS，其中像素和读出电路分别在像素和逻辑晶片中实现，从而允许每个晶片工艺针对其自身目的进行优化。通过在逻辑晶片中采用先进的工艺节点，可以在不影响像素晶片的情况下实现更低的功耗和更快的读出。此外，通过采用先进的工艺节点，可以在更小的面积内以更低的功耗在逻辑晶片中实现更多的图像信号处理器功能，如像素装仓模式或可切换转换增益（SCG）。</p><p>此外，小像素间距需要SF晶体管和光电二极管的尺寸收缩。SF晶体管宽度越窄，Gm越小，这是读取速度的重要参数，尤其是在高分辨率图像传感器中。在高分辨率图像传感器中，每个像素阵列列的位线变得更长，导致位线稳定时间更长，导致读取速度更低。时间常数 t, 对于位线可以表示为t &#x3D; RC＝（1&#x2F;Gm+Rload）C，其中Rload和C分别是位线的负载电阻和寄生电容。从表达式中可以看出t 与Gm成反比。</p><p>较小的光电二极管尺寸降低FWC和暗特性。为了获得更高的FWC，必须增加光电二极管的n型离子注入剂量和光电二极管之间隔离处的p型离子注入量，以实现合理的隔离势垒。然而，增加的n型&#x2F;p-型离子注入剂量会产生高电场，从而降低通过有缺陷的光电二极管硅表面的暗电流和WP。因此，设计更小的光电二极管需要n型&#x2F;p-型离子注入剂量调谐和硅表面缺陷改善。在这项工作中，我们提出了一种新的CIS，它解决了上述与高分辨率和小像素间距图像传感器有关的问题。</p><h1 id="2-Pixel架构与技术"><a href="#2-Pixel架构与技术" class="headerlink" title="2. Pixel架构与技术"></a>2. Pixel架构与技术</h1><h2 id="2-1-Sensor架构"><a href="#2-1-Sensor架构" class="headerlink" title="2.1 Sensor架构"></a>2.1 Sensor架构</h2><p>下图显示了传感器的框图和横截面，该传感器使用OmniVision Gen2堆叠技术：</p><p><img src="/img/11_Ovt200MpSensor/SensorBlock.png" alt="Sensor Block"></p><p>传感器晶片采用CIS专用40nm工艺节点。在逻辑晶片中，新采用了22nm工艺节点，而不是我们以前的小像素堆叠传感器中使用的40nm工艺节点。模拟和数字电路针对22nm工艺节点进行了设计和优化，与40nm工艺节点相比，实现了更低的功耗和更高的读出速度。</p><p>传感器的像素阵列大小为200兆像素（16384（H）x 12288（V）），光学格式为1&#x2F;1.28”，像素间距为0.61µm。采用2x4共享架构，其电路示意图如下所示：</p><p><img src="/img/11_Ovt200MpSensor/PixelArch.png" alt="Pixel Arch"></p><h2 id="2-2-Pixel布局"><a href="#2-2-Pixel布局" class="headerlink" title="2.2 Pixel布局"></a>2.2 Pixel布局</h2><p>下图显示了本工作中使用的传统布局和新布局之间的像素晶体管布局转变比较（左为传统布局，右为新布局）：</p><p><img src="/img/11_Ovt200MpSensor/layout.png" alt="Layout"></p><p>每个晶体管通过浅沟槽隔离（STI）进行隔离。在新布局中，两个SF通过金属布线并联连接，这提供了更大的SF宽度。通过采用垂直传输门（VTG），可以将光电二极管转移到更深的硅区域，允许在光电二极管上放置晶体管，从而在晶体管设计中提供更大的灵活性。两个SF的较大SF宽度即使在较小的像素间距中也可以提高Gm，从而在200兆像素CIS中给出合理的位线时间常数。我们还采用了背面深沟槽隔离（BDTI）来隔离每个像素，改善了光学串扰。STI、VTG和BDTI的组合允许对正面和背面硅进行独立的布局优化，使其适合小像素开发。此外，正如上图所示，我们可以包括一个额外的晶体管，它可以用于高动态应用的SCG。</p><h2 id="2-3-Pixel性能改进"><a href="#2-3-Pixel性能改进" class="headerlink" title="2.3 Pixel性能改进"></a>2.3 Pixel性能改进</h2><p>下图显示了深度方向上传感器光电二极管电位剖面的TCAD模拟：</p><p><img src="/img/11_Ovt200MpSensor/vtg.png" alt="VTG Depth"></p><p>通过增加n型&#x2F;p-型离子注入剂量和优化电势分布，避免了像素间距收缩导致的FWC降低。我们可以看到，在不牺牲滞后或开花的情况下，潜力在深度上平滑地扩展以增加FWC。然而，由于位于缺陷硅表面的较高电场而导致的暗电流或WP的退化是另一个问题，特别是在通过蚀刻工艺产生缺陷的BDTI界面中。我们采用了最新的BDTI流程，从而改进了WP。</p><p>由于较小的片上透镜（OCL）填充因子，小间距像素遭受显著的QE退化。QPD，或具有2x2 OCL的Quad Bayer编码，是一种在2x2像素阵列中使用一个OCL和相同滤色器的设计，可产生高分辨率和高动态范围的图像传感器。QPD是改善小像素图像传感器量化的一项重要技术，并在本工作中得到了实现。</p><h1 id="3-实验与对比"><a href="#3-实验与对比" class="headerlink" title="3. 实验与对比"></a>3. 实验与对比</h1><h2 id="3-1-帧率-Gm指标"><a href="#3-1-帧率-Gm指标" class="headerlink" title="3.1 帧率&amp;Gm指标"></a>3.1 帧率&amp;Gm指标</h2><p>与40nm工艺节点相比，22nm工艺节点能够在保持相同时钟频率的同时将数字功耗降低一半，并将FHD帧率从240fps提高到480fps。同时与0.7µm相比，0.61µm像素显示出63%的SF-GM改善，在2亿像素图像传感器中实现了合理的位线常数，如下图所示：</p><p><img src="/img/11_Ovt200MpSensor/cap_improve.png" alt="性能提升"></p><h2 id="3-2-满井容量"><a href="#3-2-满井容量" class="headerlink" title="3.2 满井容量"></a>3.2 满井容量</h2><p>下图显示了与像素间距相关的FWC趋势：</p><p><img src="/img/11_Ovt200MpSensor/fwc.png" alt="FWC"></p><p>填充的圆圈和虚线代表了基于1.0µm像素的简单像素区域缩放所实现的FWC。空圈显示了我们上一代0.8µm和0.7µm技术的数据。可以看出，0.8µm和0.7µm FWC远高于简单缩放预测的值；这一改进是由深光电二极管技术实现的，该技术在深硅地区精心设计了潜力。我们采用了同样的技术，我们重新设计了0.61µm，在没有滞后的情况下实现了5.0KE-FWC。</p><h2 id="3-3-白像素数量"><a href="#3-3-白像素数量" class="headerlink" title="3.3 白像素数量"></a>3.3 白像素数量</h2><p>与0.7µm相比，0.61µm像素的WP直方图有所改善，如下图所示：</p><p><img src="/img/11_Ovt200MpSensor/wp_hist.png" alt="WP直方图"></p><p>尽管我们增加了N型&#x2F;P型离子注入剂量，导致电场更高，但与上一代相比，我们最新的BDTI技术使WP得到了改善。</p><h2 id="3-4-QE"><a href="#3-4-QE" class="headerlink" title="3.4 QE"></a>3.4 QE</h2><p>下图显示了0.7µm和0.61µm像素之间的QPD QE曲线比较：</p><p><img src="/img/11_Ovt200MpSensor/qe_compare.png" alt="QE Compare"></p><p>在可见光范围内，总体QE性能与0.7µm QPD相当，但在近红外区域可以看到一些退化。</p><h1 id="4-结论"><a href="#4-结论" class="headerlink" title="4. 结论"></a>4. 结论</h1><p>我们开发了一种新的40&#x2F;22nm 200兆像素堆叠图像传感器，像素大小为0.61µm。表1显示了0.7µm和0.61µm像素之间的性能比较。数字功耗降低了一半，FHD帧速率从240fps提高到480fps。我们的SF-Gm提高了63%。与0.7µm像素相比，实现了5.0keFWC，没有滞后或开花，具有更好的WP性能。我们展示了在可见光范围内与0.7µm相当的QPD QE性能。</p><p>最后，该传感器拍摄的样本图像如下图所示：</p><p><img src="/img/11_Ovt200MpSensor/Demo_image.png" alt="Demo Image"></p><h1 id="5-结束语"><a href="#5-结束语" class="headerlink" title="5 结束语"></a>5 结束语</h1><p>今天我们为大家介绍了豪威在IEEE中发表的手机端CIS传感器的技术论文，为大家介绍了消费级Sensor的实现原理与技术架构，可以看出相对于车载CIS，消费级Sensor一般不采用DCG、SubPixel等方式提高DR，因为这样会导致成本的提升。同时其Pixel Size相对于车载也小了很多，因此移动手机端实现HDR的方式一般为多帧曝光合成的方式，这也就是为什么在手机拍摄时移动会造成明显的伪影。</p><p>好了今天就到这里，希望今天可以给您带来对于传感器的更深的认知，喜欢的同学可以进行朋友圈分享以及点击文章在看。另外，对论文感兴趣的同学可以fllow我的<a href="https://github.com/JokerEyeAdas/AdasTechPapers">Github论文仓库AdasTechPapers</a>，公众号回复较慢，后续讲解的论文会在仓库中开源。</p><hr><p><strong>如果您对ADAS感兴趣，欢迎关注我的公众号、知乎、Github、CSDN等，同时发表文章中使用源码以及文章会在我的GitHub进行开源，如果您有感兴趣话题也可以后台私信。</strong></p>]]></content>
    
    
    <categories>
      
      <category>CMOS SENSOR</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CMOS SENSOR</tag>
      
      <tag>OVT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ADAS-CIS|三星车载DRAM+大小像素HDR技术解析</title>
    <link href="/2023/10/04/10.%E4%B8%89%E6%98%9F%E8%BD%A6%E8%BD%BDCIS%E4%B9%8BSubPixel+Dram%E6%8A%80%E6%9C%AF/"/>
    <url>/2023/10/04/10.%E4%B8%89%E6%98%9F%E8%BD%A6%E8%BD%BDCIS%E4%B9%8BSubPixel+Dram%E6%8A%80%E6%9C%AF/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>在之前的文章中，我们根据索尼和安森美发表的IEEE论文，分别介绍了索尼车载CIS的大小Pixel的HDR技术以及安森美Lofic HDR技术，并分别讲述了各自的Pixel架构、优势。</p><p>今天，我们再来介绍三星车载团队在2022年于IEEE发布的1H1架构的论文，我们将介绍<a href="https://semiconductor.samsung.com/image-sensor/automotive-image-sensor/">1H1</a>是如何在pixel size为2.1um的情况下，通过使用亚像素结构和每个像素的高容量DRAM电容器，在85°C时，单次曝光动态范围达到140dB且支持LED闪烁缓解。即使电容非常高，小型光电二极管的双转换增益电路使Sensor的信噪比在105°C时可以保持在23dB以上。同时，全深度深沟槽隔离即使在极高照度的条件下也能防止像素之间的电串扰，并在0.83e-的低随机噪声下实现高转换增益。</p><p><img src="/./img/10_SamsungHDR/sensor_img.png" alt="1H1"></p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>动态范围（DR）一直是CMOS图像传感器（CIS）在汽车应用中的主要要求。高动态范围（HDR）图像提高了在高级驾驶辅助系统（ADAS）所需的所有光线条件下对物体、障碍物和交通信号的精确感知。多重曝光是CIS中使用的HDR方法之一，但图像的不同采样时间会在图像合成过程中导致运动伪影。此外，交通信号灯或车辆中使用的发光二极管（LED）会闪烁，导致信号检测或物体识别出现错误的可能性很高。</p><p>汽车应用中更优选的方法是单次曝光法，通过引入横向溢出积分电容器（LOFIC）来最大化DR。由于曝光时间比LED闪烁周期长，LED闪烁减轻（LFM），而由于长曝光时间而产生的多余信号电荷存储在LOFIC中，从而扩展DR。亚像素结构也是扩展单次曝光DR的有效方法，将高灵敏度和低灵敏度光电二极管与LOFIC相结合。然而，单次曝光DR仍接近120dB，需要额外的多次曝光或自动曝光控制来补偿不足的DR。此外，由于像素内电容器的面积有限，像素收缩会导致DR退化。</p><p>在这项工作中，我们提出了一个像素的原型来解决这些问题。该像素设计用于在单次曝光中扩展DR，改善运动伪影并支持LFM。像素大小为2.1μm，测试芯片的分辨率为830万像素。该像素采用子像素结构、全深度深沟槽隔离（F-DTI）和用于LOFIC的高容量DRAM电容器。</p><p>今天，我们继续从三星发布的IEEE的技术论文出发，来讲解新进车载Sensor厂商三星的最新的pixel架构技术。</p><h1 id="2-Sensor与像素架构"><a href="#2-Sensor与像素架构" class="headerlink" title="2. Sensor与像素架构"></a>2. Sensor与像素架构</h1><h2 id="2-1-Pixel架构"><a href="#2-1-Pixel架构" class="headerlink" title="2.1 Pixel架构"></a>2.1 Pixel架构</h2><p>Samsung论文中给出的Pixel架构如下所示：</p><p><img src="/img/10_SamsungHDR/pixel_arch.png" alt="像素架构"></p><p>上图显示了1H1的像素的示意图，像素由两个光电二极管（PD）、四个浮动扩散区（FD）、九个晶体管和一个DRAM电容器组成。大的PD（LPD）可以在黑暗条件下以高灵敏度集成大量光子，而小的PD（SPD）即使在明亮条件下也由于低灵敏度而不容易饱和。DRG晶体管控制LPD以支持双转换增益（DCG）读出。SW晶体管选择性地将SPD的FD3节点连接到源极跟随器（SF）放大器。TSW晶体管控制SPD以在DCG读出中操作。DSW晶体管缩短了电容器的放电路径，减少了DRAM电容器的稳定时间。</p><h2 id="2-2-Pixel垂直结构"><a href="#2-2-Pixel垂直结构" class="headerlink" title="2.2 Pixel垂直结构"></a>2.2 Pixel垂直结构</h2><p>下图显示了F-DTI像素的垂直结构。</p><p><img src="/img/10_SamsungHDR/SensorPixelvec.png" alt="Sensor垂直结构"></p><p>LPD和SPD具有不同尺寸的光电二极管和微透镜，具有不同的灵敏度。PD之间的F-DTI电隔离并减少光学串扰。电隔离是至关重要的，因为LPD的多余电荷应该干净地排放到VDD，在非常高的照度条件下不会影响SPD信号。它还有助于确保全井产能（FWC）。掩埋的PD通过P阱与硅表面的其他元件（例如像素晶体管或FD）电隔离，并且LPD的高转换增益是可能的，而没有任何FWC退化。</p><p>另外，全局快门CIS采用了高容量DRAM电容器以在电压域存储信号。我们引入DRAM电容器作为LOFIC到电荷域。DRAM电容器由每个像素63个凹孔组成。每个孔的尺寸为100nm，并且具有电介质ZrO&#x2F;AlO多层膜的约5fF的电容。由此产生的电容高达280fF，存储的电荷超过每像素1.8Me-。在DRAM电容器的有效25Me-FVC下，LPD和SPD之间的灵敏度比为14:1。</p><h1 id="3-像素操作"><a href="#3-像素操作" class="headerlink" title="3. 像素操作"></a>3. 像素操作</h1><p>下图分别显示了Sensor像素的时序图，其中LPD-HCG（R1-S1）和SPD-HCG（R3-S3）操作相关双采样，而LPD-LCG（S2-R2）和SPD-LCG（S4-R4）操作非相关双采样。</p><p><img src="/img/10_SamsungHDR/Timing.png" alt="时序图"></p><ul><li><p>对于LPD：（a-1）通过快门操作重置LPD。（b-1）在积分时间期间在每个光电二极管中产生信号电子。在LPD被填充之后，多余的电子被排放到VDD而不发生晕染。（c） FD1和FD2被复位，LPD-HCG在RG&#x2F;DRG关断时首先被采样（R1）。然后（d）在LTG操作期间信号电子转移到FD1，信号（S1）电平被采样。（e） 由于FD1的小电容，在DRG接通的LPD-LCG模式期间，LPD中的过量的信号电子随后转移到FD1+FD2。RG操作的kTC噪声仍然存在，但转换时的噪声电平远小于信号电平，维持了超过25dB的相当高的SNR。</p></li><li><p>对于SPD：（a-2）SPD通过快门操作重置。（b-2）来自SPD的多余电子可以依次溢出到连接到DRAM电容器的FD3和FD4，然后存储。（b-3）由于SW的关断电压低于TSW，所以溢出的电子不被排放到VDD，直到DRAM电容器完全充满信号电子为止。（g） SW开关接通，FD3连接到FD1+FD2。SPD-HCG的复位电平被采样（R3），并且SPD中的（h）信号被传送到FD1+FD2+FD3。TSW被关断，FD3和FD4被分别采样（S3），使得能够在SPD下进行HCG操作。（i） 通过接通TSW开关，FD4连接到FD1+FD2+FD3，然后对信号电平（S4）进行采样。（j） 由于DRAM电容器中可以存储大量电荷，DSW开关通过缩短DRAM电容的放电路径来帮助快速放电，并且对SPD-LCG的复位电平（R4）进行采样。</p></li></ul><h1 id="4-工作总结与其它工作对比"><a href="#4-工作总结与其它工作对比" class="headerlink" title="4 工作总结与其它工作对比"></a>4 工作总结与其它工作对比</h1><h2 id="4-1-芯片指标"><a href="#4-1-芯片指标" class="headerlink" title="4.1 芯片指标"></a>4.1 芯片指标</h2><p>下图总结了我们测试芯片的像素性能（可以看出和<a href="https://semiconductor.samsung.com/image-sensor/automotive-image-sensor/isocell-auto-1h1/">三星官网1H1介绍</a>给出的规格一致，基本确定1H1）：</p><p><img src="/img/10_SamsungHDR/spec.png" alt="Spec"></p><p>DRAM电容器的FWC为1.8Me-，这个指标相较于其他竞品sensor有较大的提高。另外，根据EMVA标准1288，在Tj&#x3D;85°C时可实现140dB的单次曝光DR。由于LPD-HCG的高CG，暗随机噪声为0.83e-，基于简单的DR计算，导致单次曝光DR为150dB。</p><h2 id="4-2-SNR性能"><a href="#4-2-SNR性能" class="headerlink" title="4.2 SNR性能"></a>4.2 SNR性能</h2><p>下图显示了105°C下由4种类型的信号组成的合成SNR曲线。</p><p><img src="/img/10_SamsungHDR/SNR.png" alt="SNR Curve"></p><p>SNR在每个过渡点都会下降，但保持在23dB以上。由于DRAM电容器导致的非常低的CG降低了随机噪声，导致SPD的过渡中严重的SNR下降。使用TSW的DCG实现了高转换增益，以减少随机噪声并提高转换SNR。SPD-LCG的转换SNR主要受随机噪声和kTC噪声的影响，这是由于非常低的转换增益，而不是FD暗信号不均匀性（DSNU）。SPD-HCG的高FWC是通过将转变点转移到更高照度条件来提高SPD-LCG的转变SNR的最有效的方式。因此，我们将FWC增加到比LPD大13keSPD。</p><h2 id="4-3-实拍图像对比"><a href="#4-3-实拍图像对比" class="headerlink" title="4.3 实拍图像对比"></a>4.3 实拍图像对比</h2><p>下图显示了在户外阳光带有LED信号下拍摄的HDR图像与传统商业相机对比:</p><p><img src="/img/10_SamsungHDR/pic.png" alt="实拍图像对比"></p><p>上图分别来自传统移动相机、120dB DR传感器和140dB DR传感器。由于曝光时间短，LED闪烁，来自移动相机的图像无法检测到来自LED的信息。然而，120dB和140dB DR传感器的单次曝光图像可以识别LED信号，并且暗区的噪声比移动相机的噪声小得多。来自140dB DR传感器的图像即使在阳光直射下也显示出更高的饱和点，并且可以区分太阳附近的LED信号。而来自120dB DR传感器中的图像由于早期饱和而丢失了一些LED信息。这意味着在非常强的照明环境中，甚至超过120dB DR，仍然需要LFM，以不丢失LED的对象、信号或信息。</p><h2 id="4-4-其他工作对比"><a href="#4-4-其他工作对比" class="headerlink" title="4.4 其他工作对比"></a>4.4 其他工作对比</h2><p>下表显示了本文工作与其他工作的性能比较：</p><p><img src="/img/10_SamsungHDR/compare.png" alt="工作对比"></p><p>论文中前三项分别为本文工作、AR0821以及IMX490（笔者估计）。可以发现即使是2.1μm的像素，有效FWC和单次曝光DR也达到了最佳值，在105°C的信噪比接近23dB。同时，FWC容量也相对比其他工作有了较大的提高。</p><p>这项工作的目的是将具有LFM支持的DR扩展到汽车应用中，因从开发了一个2.1μm像素，利用亚像素结构、F-DTI和DRAM电容器技术，实现了高达140 dB的单次曝光DR和0.83e-的低噪声的车载CIS传感器。</p><h1 id="5-结束语"><a href="#5-结束语" class="headerlink" title="5 结束语"></a>5 结束语</h1><p>今天我们为大家介绍了三星在IEEE中发表的1H1的技术论文，为大家介绍了其HDR的实现原理与技术架构，希望可以给您带来对于传感器的更深的认知，喜欢的同学可以进行朋友圈分享以及点击文章在看。</p><p>另外，对论文感兴趣的同学可以fllow我的<a href="https://github.com/JokerEyeAdas/AdasTechPapers">Github论文仓库AdasTechPapers</a>，公众号回复较慢，后续讲解的论文会在仓库中开源。</p><hr><p><strong>如果您对ADAS感兴趣，欢迎关注我的公众号、知乎、Github、CSDN等，同时发表文章中使用源码以及文章会在我的GitHub进行开源，如果您有感兴趣话题也可以后台私信。</strong></p>]]></content>
    
    
    <categories>
      
      <category>CMOS SENSOR</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CMOS SENSOR</tag>
      
      <tag>SAMSUNG</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SONY/OV车载新品|本月车载CIS新品资讯与厂家技术趋势解读</title>
    <link href="/2023/09/23/9.%E6%96%B0%E8%BD%A6%E8%BD%BDCIS%E8%B5%84%E8%AE%AF/"/>
    <url>/2023/09/23/9.%E6%96%B0%E8%BD%A6%E8%BD%BDCIS%E8%B5%84%E8%AE%AF/</url>
    
    <content type="html"><![CDATA[<p><img src="/img/9_News230925/news.jpg" alt="New"></p><h1 id="1-索尼17Mega前视应用IMX735发布-2023-09-12"><a href="#1-索尼17Mega前视应用IMX735发布-2023-09-12" class="headerlink" title="1.索尼17Mega前视应用IMX735发布(2023&#x2F;09&#x2F;12)"></a>1.索尼17Mega前视应用IMX735发布(2023&#x2F;09&#x2F;12)</h1><p><a href="https://www.sony-semicon.com/en/news/2023/2023091201.html">IMX735官网链接传送门</a></p><hr><h2 id="1-1-芯片概述"><a href="#1-1-芯片概述" class="headerlink" title="1.1 芯片概述"></a>1.1 芯片概述</h2><p>索尼半导体解决方案将推出用于汽车摄像头的CMOS图像传感器，具有业界领先的17.42百万有效像素，是目前车载领域有效像素最高的传感器芯片，为自动驾驶提供先进的传感和识别性能，为安全可靠的自动驾驶做出贡献。</p><p><img src="/img/9_News230925/IMX735.png" alt="IMX735"></p><p>对于实现自动驾驶的自动化系统，它们必须提供复杂、高精度的传感和识别性能，涵盖车辆周围的所有360度环境。因此，对能够帮助实现这种性能水平并支持更先进的汽车摄像头系统开发的图像传感器有相当大的需求。</p><p>新的传感器产品实现了业界最高的像素数，有效像素达到17.42百万，能够高清捕捉远处的物体。此外，自动驾驶系统通常将汽车摄像头与激光雷达和其他传感系统结合使用。典型的 CMOS 图像传感器每次从像素读出一行垂直线的信号，而该产品一次一行地水平输出信号。这意味着采用该传感器的汽车摄像头可以更轻松地与机械扫描 LiDAR同步，因为它们的激光束也水平扫描。这种更好的同步将提高整个自动驾驶系统的传感和识别能力。</p><h2 id="1-2-芯片特点"><a href="#1-2-芯片特点" class="headerlink" title="1.2 芯片特点"></a>1.2 芯片特点</h2><ul><li><p>业界领先的17.42兆像素实现远距离识别<br>得益于业界最高有效像素17.42兆像素，新传感器能够进行高清拍摄，将物体识别范围扩展到更远的距离，从而实现更好的识别效果。检测道路状况、车辆、行人等物体。驾驶时及早检测远处物体有助于提高自动驾驶系统的安全性。<br><img src="/img/9_News230925/17Mega.png" alt="像素对比"></p></li><li><p>水平像素信号输出，更容易与机械扫描激光雷达同步<br>当从像素读取信号时，传统的CMOS图像传感器在垂直方向一次一行读取。而IMX735采用一次水平输出一行信号的读出方法，更容易与同样采用水平扫描方法的机械扫描激光雷达同步。这意味着配备该产品的汽车摄像头输出的信息可以与系统下游的激光雷达信息集成。这将提高整个自动驾驶系统的传感和识别能力。</p></li></ul><p><img src="/img/9_News230925/Lidar_CIS.png" alt="扫描方式"></p><ul><li><p>即使同时使用 HDR 和 LED 闪烁抑制功能，也能实现宽动态范围<br>在汽车驾驶中，即使在隧道入口和出口等亮度差异较大的道路环境中，也必须精确检测和识别物体。即使在 HDR 模式下，汽车摄像头也需要抑制LED闪烁，以应对LED信号和其他交通设备日益普及的情况。该产品专有的像素结构和独特的曝光方法提高了饱和照度，即使同时采用HDR和LED闪烁缓解功能，也能产生106 dB的宽动态范围（使用动态范围优先模式时，范围更宽，为130dB）。这种设计还有助于减少运动伪影*6捕捉移动物体时生成。</p></li><li><p>符合汽车应用所需标准<br>该产品已通过批量生产，通过AEC-Q100 Grade 2汽车电子元件可靠性测试。此外，SSS还推出了符合ISO 26262 道路车辆功能安全标准（汽车安全完整性级别 ASIL-B(D)）的开发流程。这有助于提高汽车摄像系统的可靠性。</p></li><li><p>汽车应用所需的网络安全（可选）<br>该产品可支持网络安全功能，例如通过公钥算法进行摄像头身份验证以确认 CMOS 图像传感器的真实性、图像身份验证以检测对所获取图像的任何篡改以及通信身份验证以检测任何篡改控制通讯。</p></li></ul><h2 id="1-3-主要规格"><a href="#1-3-主要规格" class="headerlink" title="1.3 主要规格"></a>1.3 主要规格</h2><p>芯片主要规格如下：<br><img src="/img/9_News230925/MainSpec.png" alt="IMX735主要规格"></p><h2 id="1-4-笔者解读"><a href="#1-4-笔者解读" class="headerlink" title="1.4 笔者解读"></a>1.4 笔者解读</h2><p>相对比OV以及ONSmei，索尼是第一个推出17Mega像素的厂家，也表现了索尼未来站位高分辨率CIS的决心，同时架构依然是SubPixel HDR技术，但具体细节还要等后续笔者了解以及官方论文出来再行解读。</p><p>另一方面，分辨率的提高确实会带来更远的视野，但是同样后端算力相对于8Mega也提高了一倍多。同时、镜头成本、芯片功耗、Serdes成本的提高等都是需要解决的问题，让我们敬请期待其市场反馈如何。</p><h1 id="2-豪威科技8Mega前视应用OX08D10发布-2023-09-19"><a href="#2-豪威科技8Mega前视应用OX08D10发布-2023-09-19" class="headerlink" title="2.豪威科技8Mega前视应用OX08D10发布(2023&#x2F;09&#x2F;19)"></a>2.豪威科技8Mega前视应用OX08D10发布(2023&#x2F;09&#x2F;19)</h1><h2 id="2-1-芯片概述"><a href="#2-1-芯片概述" class="headerlink" title="2.1 芯片概述"></a>2.1 芯片概述</h2><p><a href="https://www.ovt.com/press-releases/omnivision-announces-new-theiacel-technology-and-automotive-image-sensor-for-led-flicker-free-exterior-cameras/">OX08D10官网链接传送门</a></p><hr><p>OX08D10在AutoSens布鲁塞尔展会上发布，是一款小型、低功耗图像传感器，采用OMNIVISION的全新 TheiaCel™ 技术，这个技术和安森美的技术是同一路线，即使用DCG+LOFIC技术，关于此技术可以查看公众号之前关于Onsemi技术论文的解析。</p><p>无论照明条件如何，OX08D10都能提供卓越的图像质量（待评估~），新的解决方案通过为高级驾驶员辅助系统(ADAS)和自动驾驶(AD)的外部摄像头提供更高的分辨率，更好的图像质量来增强汽车安全性。</p><p><img src="/img/9_News230925/OX08D10.png" alt="OX08D10"></p><p>OX08D10具有业界领先的低光性能和低功耗，尺寸紧凑，比同类其他外部座舱传感器小50%。它是首款采用OMNIVISION 全新2.1微米(μm) TheiaCel™ 技术的图像传感器，该技术利用下一代<code>横向溢出集成电容器(LOFIC)和OMNIVISION DCG™高动态范围(HDR)技术</code>的功能来消除LED闪烁(LFM)。TheiaCel™ 技术使OX08D10能够实现HDR图像，可视距离可达200米。该范围是在SNR1和动态范围之间提供最佳平衡的最佳点，并且是汽车外部摄像头应用的最佳选择。</p><p>OMNIVISION的全新2.1µm单像素 TheiaCel™ 技术可在不牺牲图像质量的情况下提供LFM功能。TheiaCel™ 利用下一代LOFIC功能以及OMNIVISION专有HDR 技术(专利DCG™和分离二极管技术)的成熟优势，可捕捉极高对比度的场景，以获得最佳内容和图像质量。OMNIVISION的<code>TheiaCel™ DCG™ + LOFIC</code>解决方案比早期的单曝光HDR架构实现了更宽的动态范围。</p><p>与基于LOFIC的前代产品相比，新型OX08D10在关键领域实现了整体卓越的性能。特别是保证LFM的前提下，动态范围提高了3.3倍，总动态范围提高了近3倍。它具有升级的网络安全，符合最新的MIPI CSE 2.0版标准，从而增加了汽车图像传感器数据流的功能安全性。同时TheiaCel™ 设备采用 OMNIVISION 的 a‑CSP™ 封装技术，可实现尽可能最小的解决方案。</p><p><strong>样品现已提供，OX08D10将于2024年下半年量产。</strong></p><h2 id="2-2-主要规格与产品特点"><a href="#2-2-主要规格与产品特点" class="headerlink" title="2.2 主要规格与产品特点"></a>2.2 主要规格与产品特点</h2><ul><li>芯片主要规格如下：</li></ul><p><img src="/img/9_News230925/X8DSpec.png" alt="X8D Spec"></p><ul><li>产品特点：</li></ul><p><img src="/img/9_News230925/X8DFeature.png" alt="X8D Spec"></p><h2 id="2-3-笔者解读"><a href="#2-3-笔者解读" class="headerlink" title="2.3 笔者解读"></a>2.3 笔者解读</h2><p>豪威科技目前的芯片架构最开始的9Cell、4cell大小Pixel HDR技术是从手机端演变来的技术，通过将几个小Pixel合成一个大的Pixel，然后结合DCG双转换增益实现的HDR。</p><p>以OX08B10 4Cell为例，可以认为单个小Pixel实际Pixel Size只有1.05um，三个合成大Pixel面积为3*1.05^2 &#x3D; 3.3075，如下所示：</p><p><img src="/img/9_News230925/FourCell.png" alt="FourCell-HDR"></p><p>而目前LOFIC+DCG技术则是通过扩展电容实现的HDR，无小pixel，因此单个像素的面积为2.1^2 &#x3D; 4.41。</p><p><img src="/img/9_News230925/tech.png" alt="技术演变"></p><p>直观上带来的结果就是，在低照度场景上X8D的效果会相比于X8B有较好的提升。同时，由于只有一个Pixel，省去了SubPixel带来的标定步骤以及SNR差等问题，相信Sensor指标以及图像效果会比前一代有质的提升。</p><h1 id="3-结束语"><a href="#3-结束语" class="headerlink" title="3.结束语"></a>3.结束语</h1><p>目前汽车市场百花争鸣，自动驾驶高速发展，软件不断更迭，同时对CIS传感器的需求也不断提升，各个Sensor厂商也不断推出自家新品。竞争的同时也带来行业技术的进步，同时也给消费者带来更好的用户体验。</p><p>好了今天的介绍就到这里，希望今天的介绍以及科普对您有所帮助。</p><hr><p><strong>应公众号粉丝需求，最近在整理资料以及筹备建车载传感器领域交流群，欢迎后台私信 “ADAS传感器行业交流群” 获取进群方式，预计10月份Ready，回复较慢还望谅解。同时，如果您对ADAS感兴趣，欢迎关注我的公众号、知乎、CSDN以及Github。文章中使用源码、文章会在我的GitHub进行开源。</strong></p>]]></content>
    
    
    <categories>
      
      <category>CMOS SENSOR</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CMOS SENSOR</tag>
      
      <tag>ADAS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>EVS相机|一文了解索尼EVS传感器原理、芯片架构</title>
    <link href="/2023/09/08/8.Evs%E7%9B%B8%E6%9C%BA%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    <url>/2023/09/08/8.Evs%E7%9B%B8%E6%9C%BA%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>基于事件的（Event-Based，EB）视觉传感器像素单独检测像素时域亮度对比度是否超过预设的相对阈值，以追踪相对光变化（Contrast Detection，CD），并定义采样点无关于帧的测量绝对能量（Exposure Measurement，EM）。由于记录数据的时间精度和固有抑制，固有抑制时间冗余导致后处理成本的降低、宽场景的动态范围等特性，EB传感器在高速、低功耗机器视觉中越来越受欢迎。</p><p>本文基于Sony官网对于EVS相机的表述以及Sony发表的EVS相机论文，对EVS相机的原理、Sensor架构进行展开描述，对论文感兴趣的童鞋可以在我的Github中<a href="https://github.com/JokerEyeAdas/AdasTechPapers">AdasTechPaper</a>中阅读。</p><p><img src="/img/8_EVS/p-11_mv_pc.png" alt="Evs Chip"></p><p><strong>本文首发于公众号与个人博客ADAS之眼，其他平台同步更新。</strong></p><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h1><h2 id="1-1-基本概念"><a href="#1-1-基本概念" class="headerlink" title="1.1 基本概念"></a>1.1 基本概念</h2><p>基于事件的视觉传感器（EVS，Event-Based Vision Sensor）是一种生物启发的传感器，通过将输出数据限制为每个像素的亮度变化，并结合坐标和时间信息，实现低延迟的高速数据输出。它们以物体的运动为重点，捕捉物体的详细运动，更适合用于开发作为机器的“眼睛”，尤其在自动驾驶领域。</p><p><img src="/img/8_EVS/p-11_products_evs02_en.jpg" alt="Evs"></p><p>与传统基于帧的图像传感器相比，EVS具有极快的运动捕捉，在标准的光学设置下帧率也可以达到10000fps，此外还具有高动态范围、低功耗且对片上存储需求较低。传统相机与EVS传感器图像的典型对比如下：</p><p><img src="/img/8_EVS/caompare.png" alt="Compare"></p><h2 id="1-2-论文主要工作"><a href="#1-2-论文主要工作" class="headerlink" title="1.2 论文主要工作"></a>1.2 论文主要工作</h2><p>时间对比度（CD）的信息以“事件”的形式编码：数据包含原始像素的坐标、时间戳和对比度极性。为了最大化单个像素以高精度采集信息，早期时间戳以及高度处吞吐量对于维持事件的时序非常重要。在之前的工作中，不同权衡事件精度以支持更简单的体系结构和降低输出（事件帧）的比特率的方案已经被提出。然而，这些方法与异步EB像素阵列并不能很好的匹配，限制了传感器在高速下的应用性。比如，快速时间编码结构光深度传感，高速具有kHz更新率的跟踪和光流，或可见光通信（visible-light Communication，VLC）。但本文提出的减少位&#x2F;事件数的方法是可以设计成不影响事件数据时间精度的。</p><p>另外基于事件视觉传感器，由于复杂的像素电路，长期以来一直是大像素尺寸和低分辨率。受益于直接晶圆粘合技术以及堆叠技术，实现了在背照式CIS的光子的高效转移，因此，在CMOS上实现高密度的模拟信号处理以实现具有竞争力的分辨率和尺寸具有了可能。本文介绍了一个3D堆叠EB视觉传感器，使用像素级Cu-Cu键合互连，实现4.86μm像素间距，高清分辨率低于½”光学格式。像素内电路通过失速安全低延迟接口与异步行选择树。来自活动行的事件立即被加上时间戳并被安排用于比特有效的矢量读出。数字事件信号处理（ESP）流水线具有可编程事件速率控制器（ERC）以及用于动态比特压缩的事件数据格式化器（EDF）。并行输出具有数据封装的接口（EOI）将事件数据直接提供给处理器，或连接到外部MIPI或USB收发器。</p><h1 id="2-基本原理"><a href="#2-基本原理" class="headerlink" title="2.基本原理"></a>2.基本原理</h1><h2 id="2-1-人眼模型"><a href="#2-1-人眼模型" class="headerlink" title="2.1 人眼模型"></a>2.1 人眼模型</h2><p>EVS 旨在模拟人眼感知光线的方式。人眼的工作方式是，当视网膜上的受体暴露在光线下时，会将其转换为视觉信号发送到大脑。随后的神经元细胞识别明暗，信息通过视网膜神经节细胞传递到大脑的视觉皮层。</p><p>在 EVS 中，入射光在成像器的光接收电路中转换为电信号。信号通过放大器单元并到达比较器，在比较器中差分亮度数据被分离并分为正信号和负信号，然后将其处理并作为事件输出。</p><p><img src="/img/8_EVS/BasePrincilpe.png" alt="基本原理"></p><h2 id="2-2-事件捕捉"><a href="#2-2-事件捕捉" class="headerlink" title="2.2 事件捕捉"></a>2.2 事件捕捉</h2><p>在基于事件的视觉传感器中，对每个像素检测到的亮度变化进行过滤，以仅提取超出预设阈值的亮度变化。然后，该事件数据在输出之前的像素坐标、时间和极性信息组合。每个像素异步运行，独立于其他像素。下图说明了传感器如何捕捉球的运动：</p><p><img src="/img/8_EVS/principle.png" alt="运动记录"></p><h2 id="2-3-Pixel原理"><a href="#2-3-Pixel原理" class="headerlink" title="2.3 Pixel原理"></a>2.3 Pixel原理</h2><p>每个像素由光接收和亮度检测单元组成。入射光在光接收单元中被转换成电压。亮度检测单元中的差分检测电路检测参考电压和转换后的入射光电压之间的变化。如果正方向或负方向的变化大于设定的阈值，则比较器将其识别为事件并输出该数据。简化的框架如下所示：</p><p><img src="/img/8_EVS/base_info.png" alt="基本工作流"></p><p>更具体的Pixel电子框架如下所示：</p><p><img src="/./img/8_EVS/pixel_arch.png" alt="Pixel Arch"></p><p>上图显示了一个像素框图，说明了基于对比度检测(Contrast Detection, CD)电路和异步读出接口和状态逻辑（Interface and State-logic,ISL）的CIS前后端块，它带有Cu-Cu内联的CMOS异步增量调制（asynchronous delta-modulation, ADM）。CON&#x2F;COFF的输入锁存器在比较器切换缓慢的情况下降低功率，并防止切换点周围的振铃。门控锁存器（K）可以鲁棒的进行事件注册来防止延迟regx生成和由此产生的事件丢失；行读出开始后的事件驱动在当前周期一结束（去除acky）就被锁存用于后续读出。只有输入锁存器中存储有事件的像素，本地生成GTRLAOU以在接收acky时重新初始化其CD电路，从而消除了对逐列ackx信号的必要性，并简化了读出控制逻辑、列读出电路和像素阵列信号输出。</p><p>其中，LogI&#x2F;V电路以及ISL状态逻辑逻辑电路如下所示：</p><p><img src="/./img/8_EVS/pixel_arch_detail.png" alt="Pixel Arch Detail"></p><h1 id="3-芯片架构"><a href="#3-芯片架构" class="headerlink" title="3.芯片架构"></a>3.芯片架构</h1><h2 id="3-1-Sensor-Block"><a href="#3-1-Sensor-Block" class="headerlink" title="3.1 Sensor Block"></a>3.1 Sensor Block</h2><p>下图显示了芯片的框图，说明了像素阵列读出以及事件数据经由ESP Pipeline到输出数据接口的框架：</p><p><img src="/img/8_EVS/Sensor%20Block.png" alt="Sensor Block"></p><p>活动行选择的操作是流水的，新行选择与前一行数据的处理是并行的。异步到同步接口是由像素远端行的超时列监督，确保以正确的时序将VecX数据同步到与ESP Pipeline，并且防止由于异步数据路径导致的运行时间的事件丢失。时间戳会附加在事件上一起发送到输出数据接口。这种读出结构保证了像素阵列的事件时间精度。典型的像素激活到时间戳输出的延迟在60-70ns，另外行到行的选择时序约120ns的延迟。</p><h2 id="3-2-事件信号处理"><a href="#3-2-事件信号处理" class="headerlink" title="3.2 事件信号处理"></a>3.2 事件信号处理</h2><p>下图显示了ESP管道和输出接口的框图：</p><p><img src="/img/8_EVS/pipeline.png" alt="Pipeline"></p><p>ESP功能包括地址过滤、吞吐量调节和数据格式化。数字读出（RO）块逐行同步以及像素事件数据打时间戳，并且将它们分为32个事件向量。基于LUT的地址过滤器去除所选事件，例如，来自缺陷像素的事件。</p><p>ERC块允许通过在超过该值的峰值上动态应用数据下降来将输出事件速率限制为预定义的极限速率。极限速率可在每秒5k事件（EPS）和1GEPS之间的大范围内编程。ERC持续监控FIFO缓冲器的输入和输出速率，并在闭环配置中，通过移除事件来调节瞬时FIFO输出速率，遵循结合空间和时间标准的各种丢弃策略。</p><p>基于ROI的投放方案将像素阵列细分为40×23的32×32像素块，这些像素块可以编程为每个块执行64个可选称重投放速率中的不同一个，从而实现ERC操作的特定应用优化（例如，最好是在汽车场景中从天空中投放事件）。EDF块将事件流转换为矢量化数据格式（EVT）。高级EVT格式结合了差分编码和矢量化编码，通过利用事件之间的空间和时间关系来动态优化每个事件的比特数。</p><p>在吞吐量最高的情况下，平均1.6b对事件的全部时间和空间信息进行编码。EOI管理芯片外数据传输，提供了对本机管理多个事件粒度的持久性支持。除了16b并行100MHz同步模式外，该接口还可以配置为分组模式，以更好地适应USB&#x2F;MIPI收发器。时钟门控降低EOI功耗。ESP集成了管道沿线不同位置的自动测试模式生成器（ATPG）以简化芯片验证。</p><h1 id="4-工作总结"><a href="#4-工作总结" class="headerlink" title="4.工作总结"></a>4.工作总结</h1><h2 id="4-1-传统传感器对比"><a href="#4-1-传统传感器对比" class="headerlink" title="4.1 传统传感器对比"></a>4.1 传统传感器对比</h2><p>下图展示了传感器的典型应用：</p><ul><li>传统相机应用，约~1lux的亮度场景选，演示了在实验室中测试的与传统相机低光对比度灵敏度结果。</li></ul><p><img src="/img/8_EVS/automovtive.png" alt="Automotive"></p><ul><li>3D视觉应用对比，由于时间的高精度、低延迟以及高速读出时间的操作允许传感器在时域编码结构光Pattern以实现3D视觉应用。</li></ul><p><img src="/img/8_EVS/ToF.png" alt="3D ToF"></p><h2 id="4-2-其他工作对比"><a href="#4-2-其他工作对比" class="headerlink" title="4.2 其他工作对比"></a>4.2 其他工作对比</h2><p>文末作者给出了与其他厂家sensor的对比，如下：</p><p><img src="/img/8_EVS/WorkCompare.png" alt="其它工作对比"></p><p>当然，论文和实际一般存在gap，但从数据上来看，sony的evs sensor从工艺、数据速率、动态范围上都有较大的提升。</p><h2 id="4-3-工作总结"><a href="#4-3-工作总结" class="headerlink" title="4.3 工作总结"></a>4.3 工作总结</h2><p>本文设计并制造了一个分辨率为1280x720、1&#x2F;2英寸的EB视觉传感器，该传感器在40nm CMOS结合90nm BI CIS，完成Cu-Cu键合晶片堆叠上，具有4.86um的像素大小，实现了77%以上的填充因子。</p><p><img src="/img/8_EVS/chip_array.png" alt="Chip"></p><p>该芯片功耗为32mw（静态）至84mw的高活性（300EPS）。具有1μs时间戳的读出处理像素阵列中高达2.5GEPS的内部峰值，并在芯片输出时保持1.066GEPS。每个事件的比特被动态压缩到1.6b，同时保持完整的空间和时间信息。由于良好的低光CIS性能（40mlx LLCO）和在高光下不存在寄生光电流的泄漏活动，实现了宽DR（&gt;124dB）。在照度水平&gt;10lux时，典型的阶跃响应潜伏期约为200μs。</p><h1 id="5-结束语"><a href="#5-结束语" class="headerlink" title="5.结束语"></a>5.结束语</h1><p>今天我们给大家介绍了Sony的基于EVS芯片论文，讲解了EVS传感器的基本测量原理、芯片pixel原理、架构等。希望今天的介绍以及科普对您有所帮助。</p><hr><p><strong>如果您对ADAS感兴趣，欢迎关注我的公众号、知乎、CSDN等，同时发表文章中使用源码、文章会在我的GitHub进行开源（网页About Me中有公众号、Github等信息）</strong></p>]]></content>
    
    
    <categories>
      
      <category>EVS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ADAS</tag>
      
      <tag>EVS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ADAS-Lidar|索尼车载IMX459激光雷达芯片论文解析</title>
    <link href="/2023/08/26/4-%E7%B4%A2%E5%B0%BCIMX459%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BEDemo%E8%AE%BA%E6%96%87%E6%B5%85%E6%9E%90/"/>
    <url>/2023/08/26/4-%E7%B4%A2%E5%B0%BCIMX459%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BEDemo%E8%AE%BA%E6%96%87%E6%B5%85%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>之前我们在《<a href="https://mp.weixin.qq.com/s?__biz=MzkzNjQ0NDMyMg==&mid=2247483738&idx=1&sn=18a945bf534dcb61fa7b309b687a7e27&chksm=c29fe997f5e8608117e314616a05daf28751b6a2caa5426802132bdba93f366083f77d83b0db&token=1440854923&lang=zh_CN#rd">ADAS-激光雷原理概述</a>》中简要介绍了基于dToF的Lidar的组成、原理以及发展趋势等。今天，我们将基于Sony首款激光雷达SPAD芯片<code>IMX459</code>的IEEE论文，为大家介绍IMX459芯片以及基于该芯片的Lidar Demo的基本框架。</p><ul><li><p>索尼官网对IMX459的介绍链接： <a href="https://www.sony-semicon.com/en/products/is/automotive/tof.html">SPAD Depth Sensor for Automotive LiDAR Applications</a></p></li><li><p>Demo点云图像：</p></li></ul><p><img src="/img/4_SonyLidar/PointCloud.png" alt="IMX459点云图像"></p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>目前，LiDAR(Light Detection And Ranging)传感器在自动驾驶以及高阶辅助驾驶应用中有了极大地应用发展，它们被用于高精度测距、重建物体外形以及道路识别等各种应用。 </p><p>无论白天， 这些Lidar传感器在不损失精度的前提下可以获取极好的测量效果。过去的时间里，基于时间相关单光子计数TCSPC(Time-Correlated Single Photon Counting)以及数字信号处理器DSP(Digital Single Processing)已经实现了100m范围的ToF测距Sensor。背景噪声去除技术已经被用于提高传感器的信噪比SNR，物体的检测距离可以达到6Km。</p><p>基于单光子雪崩二极管SPAD(Single Photon Avalanche Diode)架构实现了每个pixel级别的直方图统计、时间数字转换以及信号处理。一些ToF已经可以达到较高的分辨率，如1200x900像素。随着使用2D-SPAD阵列实现的高精度固态激光雷达的迫切需求，我们提出了一个SPAD直接飞行时间（dToF）深度传感器，以实现300m远距离距离测量并且满足了在-40~125℃下的自动驾驶器件等级。</p><p><img src="/img/4_SonyLidar/dToF.png" alt="dToF"></p><p>这个基于微机电系统（MEMS）的SPAD激光雷达可以<strong>实现在10%反射率的情况下实现150m的距离测量，精度为0.1%，在反射率为95%的情况下，可以实现200m的目标距离测量，精度为0.1%。</strong></p><p>本文提出了<strong>背照-堆叠式</strong>的SPAD dToF深度传感器，在传感器上部署了无源抑制和再充电（PQR）前端电路、TCSPC和片上DSP。在自然光为117klux的条件下，这个基于微机电系统的SPAD Lidar测量范围可达200m，分辨率为168*63，帧率为20fps。</p><h1 id="2-Lidar-Demo系统架构"><a href="#2-Lidar-Demo系统架构" class="headerlink" title="2 Lidar Demo系统架构"></a>2 Lidar Demo系统架构</h1><p>Lidar传感器基于微机电系统SPAD Lidar的概念，整体系统细节如下所示：</p><p><img src="/img/4_SonyLidar/mems.png" alt="Sensor System Arch"></p><p>雷达系统主要有三部分组成：</p><ul><li>一个脉冲激光发射器</li><li>MEMS微振镜</li><li>SPAD dToF传感器</li></ul><p>激光发射器的激光波段为905nm，4.5n是的激光脉冲，峰值输出功率可达45W。在1D扫描的方式下，MEMS微振镜被用于引导激光束。<br>基于MEMS的SPAD扫描激光雷达dToF深度传感器可以达到25.2°×9.45°视场FOV，角度分辨率为0.15°，最远测量距离为300米。在这种方法中，MEMS反射镜振荡而激光垂直扫描。垂直ToF宏像素的SPAD阵列（MP）用相同的激光脉冲并行扫描所有63个垂直ToF MP，同时192个ToF宏块中的一个用于168个水平活动ToF MP。扫描速度非常高，导致以20帧&#x2F;s的速度进行168×63MP的全扫描。</p><p><strong>备注：Sensor全分辨率189x600, 3x3bining，最后分辨率63x200，最终active区域分辨率为63x192（猜测边缘8个应该是用于测环境光or单纯作为padding像素）</strong></p><h1 id="3-dToF芯片架构"><a href="#3-dToF芯片架构" class="headerlink" title="3 dToF芯片架构"></a>3 dToF芯片架构</h1><h2 id="3-1-芯片SPAD阵列"><a href="#3-1-芯片SPAD阵列" class="headerlink" title="3.1 芯片SPAD阵列"></a>3.1 芯片SPAD阵列</h2><p>芯片架构包含189x600的SPAD阵列，包括行列驱动器、置信度检测电路CDCS，TDCS以及DSP等，如下图所示：</p><p><img src="/img/4_SonyLidar/sensor_arch.png" alt="Sensor Arch"></p><p>该传感器由垂直方向189个SPAD的光接收区和水平方向上的600个SPAD组成。可选3×3 SPAD或6×6 SPAD的配置构成一个宏像素，宏像素是芯片的最小分辨率单位。</p><p>信号处理流程从CDCs到直方图采集（ACQ）、回波分析（EA）和峰值检测（PD），每个相位包括两组电路。每个电路在500MHz时钟的相反相位上处理信号，即时钟上升以及下降沿均处理信号，从而在每次测量中实现1GHz的有效采样率每隔一个阶段发生一次。ACQ之后，对两相的数据进行交替地积分，然后以250MHz单相的处理数据。</p><h2 id="3-2-输出模式"><a href="#3-2-输出模式" class="headerlink" title="3.2 输出模式"></a>3.2 输出模式</h2><p>芯片共有三种输出模式：</p><ul><li>直方图模式：可以测量距离范围内的直方图数据</li><li>回波模式：最多5个回波的直方图数据</li><li>测距模式：最多5个回波的多回波分析信息数据</li></ul><p>芯片的上采样使用FIR滤波器，可以将精度提高到7.5厘米。</p><p>传感器有两种操作模式：</p><ul><li>线性：active 区域是固定的</li><li>阵列模式：每个位置选择读出行</li></ul><h2 id="3-3-工作时序"><a href="#3-3-工作时序" class="headerlink" title="3.3 工作时序"></a>3.3 工作时序</h2><p>此传感器的同步时序由同步信号F_SYNC、S_SYNC、PRE_TRG和TRG_I等控制。同步信号时序如下图所示：</p><p><img src="/img/4_SonyLidar/sync_timing.png" alt="同步时序"></p><p>F_SYNC为50ms周期，分为S_ SYNC 63个时隙，每个时隙761.60μs。S_SYNC 63时隙用于生成63个ToF图像的垂直扫描的时段。在当前是环境背景光下，ACQ定时信号PRE_TRG被输入到该传感器，并且带有BG光的ACQ数据会被输出。采集的BG光的平均值和方差值输出给每个像素作为输出格式中的共同模式信息。这种共同模式被用于作为减去直方图ACQ中的BG光分量的值(<strong>本质就是背景光</strong>)。</p><h2 id="3-3-芯片架构"><a href="#3-3-芯片架构" class="headerlink" title="3.3 芯片架构"></a>3.3 芯片架构</h2><p>高分辨率SPAD dTOF深度传感器的框图如下图所示：</p><p><img src="/img/4_SonyLidar/PQR.png" alt="PQR Circle"></p><p>PQR前端电路由专用列和行控制驱动电路组成，物体反射的激光脉冲由光学器件聚焦并通过SPAD阵列进行检测。接收到的光子信号通过阴极高速放大。PQR前端电路中完成高速的模数转换，最后数据被TDC输出。</p><p>在数据读出器件，来自列SPAD的信号在水平方向上按照81b对齐。最后，列移位器在200个宏像素中选择192个进行读取。在室温下，使用PQR读出电路，死区时间可以缩减为6ns。</p><h1 id="4-芯片性能"><a href="#4-芯片性能" class="headerlink" title="4 芯片性能"></a>4 芯片性能</h1><h2 id="4-1-基本SPEC-工艺"><a href="#4-1-基本SPEC-工艺" class="headerlink" title="4.1 基本SPEC&amp;工艺"></a>4.1 基本SPEC&amp;工艺</h2><p>芯片的基本参数如下所示：</p><p><img src="/img/4_SonyLidar/base_spec.png" alt="基本参数"></p><p>芯片使用堆叠式工艺，顶部芯片使用90nm的背照式工艺实现，完成基于CMOS的SPAD。底部芯片使用40nm 1AI-10cu工艺，负责完成SPAD的信号逻辑处理。整个pixel数量为100000个SPAD像素(189(H)x600(V))，包含没有使用的SPAD。最终整个芯片die如下所示：</p><p><img src="/img/4_SonyLidar/chip_art.png" alt="芯片工艺"></p><p>SPAD的像素尺寸为10um，每个像素包含一个微透镜。在波长为905nm的光源下，SPAD的峰值光子检测效率（PDE）可以达到22%。在-40℃的条件下，PDE缩减14%，如下图所示：</p><p><img src="/img/4_SonyLidar/wavlength_test.png" alt="波长依赖"></p><p>关键性能如下：</p><ul><li>测量死区时间为6ns；</li><li>DCR背景计数时间计数在60℃和125℃的情况下，分别为2kcps以及600kcps；</li><li>在200μW&#x2F;cm^2的光强下，60Mcps即可达到饱和；</li><li>在117klux的光照下，可探测95%反射率的物体，芯片测量距离可达200m，精度30cm；</li></ul><h2 id="4-2-Demo效果"><a href="#4-2-Demo效果" class="headerlink" title="4.2 Demo效果"></a>4.2 Demo效果</h2><p>下图显示了基于MEMS的SPAD LiDAR测量的3D点云，俯视投影、强度图像、BG光无源图像和2D深度图像。</p><p><img src="/img/4_SonyLidar/demo.png" alt="Demo"></p><p>行人、汽车、路缘石、树木和建筑物等各种物体都可以通过SPAD dToF深度传感器检测到。同时传感器提供有效的检测距离范围为0到300m。</p><p>下图显示了在对于117klux阳光条件下，激光雷达系统对于10%反射率目标在0至150米处的测量结果：</p><p><img src="/img/4_SonyLidar/reflective.png" alt="测量精度"></p><p>这表明在117klux阳光下，95%反射率目标在150至200米处距离测量误差在150m处精度&lt;15cm，在200m处精度＜30cm。</p><h2 id="4-3-其他工作对比"><a href="#4-3-其他工作对比" class="headerlink" title="4.3 其他工作对比"></a>4.3 其他工作对比</h2><p>与最近发布的最先进技术进行比较，设备和激光雷达系统对比如下:</p><p><img src="/img/4_SonyLidar/others_compare.png" alt="其它工作对比"></p><p>传感器捕获的189x600 SPAD的背景光图像如下所示：</p><p><img src="/img/4_SonyLidar/confidence.png" alt="背景光图像"></p><h1 id="5-结束语"><a href="#5-结束语" class="headerlink" title="5 结束语"></a>5 结束语</h1><p>今天我们给大家介绍了Sony的基于SPAD dToF芯片论文，讲解了芯片基本架构、性能指标等，希望今天的介绍以及科普可以帮助您更加深入的了解车载激光雷达，对您的工作有所帮助。</p><hr><p><strong>如果您对ADAS感兴趣，欢迎关注我的公众号、知乎、CSDN等，同时发表文章中使用源码会在我的GitHub进行开源（网页About Me中有公众号、Github等信息）</strong></p>]]></content>
    
    
    <categories>
      
      <category>Lidar</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ADAS</tag>
      
      <tag>Lidar</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ADAS-Lidar|一文看懂车载激光雷达原理</title>
    <link href="/2023/08/26/7.Lidar%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D/"/>
    <url>/2023/08/26/7.Lidar%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>“ADAS激光雷达领域厮杀激烈，从最开始的纯机械32&#x2F;64&#x2F;128线到现在MEMS振镜半固态激光雷达，再到纯固态Flash补盲雷达，激光雷达在ADAS的需求之下发展的如火如荼。目前国内禾赛、速腾等厂家车规级激光雷达已经批量出货，今天我们揭秘激光雷达神秘的面纱。”</p><p><img src="/img/7_Lidar_Principle/Lidar.png" alt="Lidar"></p><h1 id="1-基本原理"><a href="#1-基本原理" class="headerlink" title="1 基本原理"></a>1 基本原理</h1><p>激光雷达本质是一个深度传感器，其测距原理是利用dToF(direct Time of Flight)飞行时间来计算，典型激光雷达点云图如下所示：<br><img src="/img/7_Lidar_Principle/point_cloud.png" alt="3D点云"></p><p>相对于dToF直接飞行时间，还有iToF(indirect Time of Flight)，这个我们后面单独开一期文章进行科普。不同于传统的如双目图像来推算三维信息，而是通过红外光在空气中的飞行时间，计算出目标体的距离。</p><p>典型的ToF相机原理如下图所示：</p><p><img src="/img/7_Lidar_Principle/principle.png" alt="ToF原理"></p><p>ToF相机主动发出红外光，光线遇到物体之后反射到ToF相机，ToF相机通过发射光以及反射光之间时间差，也就是红外光的飞行时间，通过公式来计算物体距离：</p><p>$$<br>d &#x3D; 1&#x2F;2∗c∗∆t<br>$$</p><p>其中，∆t为ToF测试时间，c为光速，d为测试物体距离。</p><p>另外，自然界的环境光也会夹杂在反射光中一起反射进入到ToF传感器中，这部分环境光对于真实反射光而言就是噪声，会降低测量的信噪比。</p><p>以目前市面上主流激光雷达如禾赛、速腾、Livox等激光雷达转镜方案为例，架构如下所示：</p><p><img src="/img/7_Lidar_Principle/arch.png" alt="Lidar架构"></p><p>可以看出一个激光雷达模组主要以下部件组成：</p><ul><li>转镜 or MEMS振镜：光路折射处理；</li><li>激光发射器：主动发射红外光源；</li><li>镜头：接收转镜反射的激光，过滤杂光；</li><li>FPGA信号处理器：信号处理以及雷达控制；</li><li>dToF Sensor，内部主要器件有：<ul><li>SPAD：单光子雪崩二极管（Single Photon Avalanche Diode）</li><li>TDC：时间数字转换器（Time to Digital Convert）<br>下面就其中的SPAD、TDC以及振镜进行介绍。</li></ul></li></ul><h1 id="3-关键电子器件"><a href="#3-关键电子器件" class="headerlink" title="3 关键电子器件"></a>3 关键电子器件</h1><p>Lidar中关键的电子器件有SPAD、TDC、振镜、DSP等，今天我们就其中的SPAD、TDC、微振镜进行介绍。</p><h2 id="3-1-SPAD"><a href="#3-1-SPAD" class="headerlink" title="3.1 SPAD"></a>3.1 SPAD</h2><p>dToF深度传感器上，SPAD像素能够检测单个光子，SPAD本质上是一个二极管，那么它就会有二极管该有的特性。</p><p>SPAD工作特性曲线如下图所示：</p><p><img src="/img/7_Lidar_Principle/spad.png" alt="SPAD"></p><p>上图来自于索尼官网，可以看出：</p><ul><li>击穿电压(VBD)施加到SPAD像素中的电极，通过设置过量偏置电压(VEX)超过VBD到电极，此时SPAD处于工作状态1。</li><li>当像素被光子击中时，此时SPAD光电转换中产生的电子通过雪崩倍增被放大，SPAD进入状态2。</li><li>然后，电极间电压降低至击穿电压并且雪崩倍增停止。此时后端收集雪崩倍增产生的电子。</li><li>电压恢复到击穿电压（淬灭作用）后，再次将电极间电压设为过剩偏置电压，从而能够检测光子（再充电作用）。</li></ul><p>整个过程，由光子到达触发的电子倍增称为盖革模式，整个过程电子变化如下所示：</p><p><img src="/img/7_Lidar_Principle/e_transfer.png" alt="电子转移"></p><h2 id="3-2-TDC"><a href="#3-2-TDC" class="headerlink" title="3.2 TDC"></a>3.2 TDC</h2><p>T<br>DC是dToF测量精度的关键器件之一，TDC原理是使用环形振荡器，通过级联反向二极管。当输入端给一个初始激励后，处于环形振荡器的每个二极管都会不断改变状态，而这个过程时间延迟很低在ps级别。开始工作后使用一个计数器进行计数便可以知道从激光发射到接收的时间差。</p><p>TDC的典型硬件原理图如下所示：</p><p><img src="/img/7_Lidar_Principle/TDC.png" alt="TDC原理"></p><p>每个SPAD像素都会进行多次测量，然后TDC的测量数据存放入Time Bin当中，Time Bin本质就是直方图统计。直方图统计每次测量反射时间的计数，直方图中的峰值即作为当前测量点的反射时间，而直方图中其他数据则为雷达身处环境中噪声，如下所示：</p><p><img src="/img/7_Lidar_Principle/historm.png" alt="TDC直方图"></p><h2 id="3-3-MEMS振镜"><a href="#3-3-MEMS振镜" class="headerlink" title="3.3 MEMS振镜"></a>3.3 MEMS振镜</h2><p>传统激光雷达是使用两个电机带动两个透镜来实现水平方向以及垂直方向的扫描，但由于一般车上的震动大、工况复杂且电机寿命无法达到十几年寿命的需求，传统方案不是激光雷达的最优解，以蔚来ET7上使用的激光雷达拆解图为例，电机带动H&amp;V方向透镜的示意图如下：</p><p><img src="/img/7_Lidar_Principle/motor_mirror.png" alt="电机转镜"></p><p>传统方案典型的弊端有两个：</p><ul><li>电机+透镜导致激光雷达整机模组体积大</li><li>电机寿命低</li></ul><p>近些年随着MEMS技术的发展，MEMS Mirror广泛开始应用于投影、激光雷达等领域，其工作原理利用了法拉第电磁感应原理，将通电的线圈中放置于磁场当中，通过改变电流的方向来改变振镜的方向，其原理如下图所示：</p><p><img src="/img/7_Lidar_Principle/mems_mirror.png" alt="Mems-Mirror"></p><h1 id="4-结束语"><a href="#4-结束语" class="headerlink" title="4 结束语"></a>4 结束语</h1><p>今天我们给大家介绍了车载激光雷达基本原理，讲解了基本原理、组成机构以及关键器件等，希望今天的介绍以及科普可以帮助您更加深入的了解车载激光雷达，对您的工作有所帮助。</p><p>最后通过速腾发布的一则视频来了解激光雷达MEMS振镜方案整体协作流程，YouTube链接传送门：</p><p><a href="https://youtu.be/dN_0uJM0Egk">视频传送门</a></p><hr><p><strong>如果您对ADAS感兴趣，欢迎关注我的公众号、知乎、CSDN等，同时发表文章中使用源码会在我的GitHub进行开源（网页About Me中有公众号、Github等信息）</strong></p>]]></content>
    
    
    <categories>
      
      <category>Lidar</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ADAS</tag>
      
      <tag>Lidar</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>开源|HDR-ISP开源项目介绍</title>
    <link href="/2023/08/15/6.%E5%BC%80%E6%BA%90HDR-ISP%E4%BB%8B%E7%BB%8D/"/>
    <url>/2023/08/15/6.%E5%BC%80%E6%BA%90HDR-ISP%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>拖更很久了，本着出品必精的原则，我们更新就来点干货。想起刚入行时，网上并没有很多以及系统的ISP的学习资料，都是边工作、边搜集资料然后边学习，一路坎坎坷坷走到今天算是刚入了ISP的大门。</p><p>为了解决新人入门的问题，给广大入门的新人一个参考的demo，我参考了各个开源的ISP，使用C++肝了一个用于HDR相机的开源ISP，用于给入门的新人参考。<strong>开源链接放在文末，有需要的自取。</strong></p><h1 id="1-项目描述"><a href="#1-项目描述" class="headerlink" title="1. 项目描述"></a>1. 项目描述</h1><h2 id="1-1-项目特点"><a href="#1-1-项目特点" class="headerlink" title="1.1 项目特点"></a>1.1 项目特点</h2><p><strong>一个使用C++编写的、用于HDR相机的ISP Pipeline</strong></p><ul><li>ISP模块使用C风格编写</li><li>除仓库文件外，无其它第三方库依赖</li><li>可以在任意支持C++的嵌入式平台上部署</li><li>可以通过json配置自定义你的pipeline</li></ul><h2 id="1-2-默认Pipeline"><a href="#1-2-默认Pipeline" class="headerlink" title="1.2 默认Pipeline"></a>1.2 默认Pipeline</h2><p><strong>默认Json配置pipeline:</strong></p><p><img src="/img/6_HDR_ISP/pipeline.png" alt="Pipeline"></p><h2 id="1-3-当前支持的模块"><a href="#1-3-当前支持的模块" class="headerlink" title="1.3 当前支持的模块"></a>1.3 当前支持的模块</h2><p><strong>支持&amp;准备支持的ISP模块列表：</strong></p><ul><li>Raw Domain<ul><li><input checked="" disabled="" type="checkbox"> MipiUnPack: Mipi原始数据转RAW16</li><li><input checked="" disabled="" type="checkbox"> DePwl: 解压缩数据</li><li><input disabled="" type="checkbox"> Dpc: 动态坏点校准</li><li><input disabled="" type="checkbox"> Lsc: 镜头阴影校准</li><li><input checked="" disabled="" type="checkbox"> Blc: 黑电平校准</li><li><input disabled="" type="checkbox"> Rns: Raw域降噪</li><li><input checked="" disabled="" type="checkbox"> WbGain: 白平衡增益</li><li><input checked="" disabled="" type="checkbox"> Demoasic: 解马赛克</li></ul></li><li>RGB Domain<ul><li><input checked="" disabled="" type="checkbox"> Ltm: 局部色调映射</li><li><input checked="" disabled="" type="checkbox"> RgbGamma: rgb伽马曲线</li><li><input checked="" disabled="" type="checkbox"> Ccm: 色彩校准矩阵</li><li><input checked="" disabled="" type="checkbox"> Rgb2Yuv: rgb域转yuv域</li></ul></li><li>YUV Domain<ul><li><input checked="" disabled="" type="checkbox"> YGamma: 灰度伽马曲线</li><li><input checked="" disabled="" type="checkbox"> Contrast: 对比度提升</li><li><input checked="" disabled="" type="checkbox"> Sharpen: 锐化边缘增强</li><li><input disabled="" type="checkbox"> Cns: 颜色滤波</li><li><input checked="" disabled="" type="checkbox"> Saturation: 色度提升</li><li><input checked="" disabled="" type="checkbox"> Yuv2Rgb: yuv域rgb域</li></ul></li></ul><h1 id="2-如何编译与运行"><a href="#2-如何编译与运行" class="headerlink" title="2. 如何编译与运行"></a>2. 如何编译与运行</h1><h2 id="2-1-Linux系统"><a href="#2-1-Linux系统" class="headerlink" title="2.1 Linux系统"></a>2.1 Linux系统</h2><p><strong>开发环境:</strong> </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#dependencies install(cmake and opencv)</span><br>sudo apt update<br>sudo apt install cmake<br></code></pre></td></tr></table></figure><p><strong>编译</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/JokerEyeAdas/HDR-ISP<br><span class="hljs-built_in">cd</span> HDR-ISP/<br><span class="hljs-built_in">mkdir</span> build<br>cmake ..<br>make -j12<br></code></pre></td></tr></table></figure><h2 id="2-2-Windows系统"><a href="#2-2-Windows系统" class="headerlink" title="2.2 Windows系统"></a>2.2 Windows系统</h2><p><strong>开发环境(x64):</strong> </p><ul><li>vs code</li><li>cmake</li><li>msvc c++ gen tool</li></ul><p><img src="/img/6_HDR_ISP/compile.png" alt="build tool"> </p><p><strong>编译</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/JokerEyeAdas/HDR-ISP<br>code HDR-ISP<br><span class="hljs-comment">#cmake 选择 Debug or Release</span><br><span class="hljs-comment">#compiler 选择 xxx-amd64</span><br><span class="hljs-comment">#build all</span><br></code></pre></td></tr></table></figure><h2 id="2-3-运行"><a href="#2-3-运行" class="headerlink" title="2.3 运行"></a>2.3 运行</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> build<br><span class="hljs-comment">#cp cfgs and data</span><br><span class="hljs-built_in">cp</span> -r ../data/ ./<br><span class="hljs-built_in">cp</span> -r ../cfgs/ ./<br><span class="hljs-comment">#run isp</span><br>./HDR_ISP ./cfgs/isp_config_cannon.json<br></code></pre></td></tr></table></figure><h2 id="2-4-参数调试"><a href="#2-4-参数调试" class="headerlink" title="2.4 参数调试"></a>2.4 参数调试</h2><p><strong>通过修改json配置来配置ISP模块的基本参数</strong></p><p>如，修改sensor基本参数：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;raw_file&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;./data/connan_raw14.raw&quot;</span><span class="hljs-punctuation">,</span><br><span class="hljs-attr">&quot;out_file_path&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;./&quot;</span><span class="hljs-punctuation">,</span><br><span class="hljs-attr">&quot;info&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;sensor_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;cannon&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;cfa&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;RGGB&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;data_type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;RAW16&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;bpp&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">16</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;max_bit&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">14</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;width&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">6080</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;height&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4044</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;mipi_packed&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><br><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br></code></pre></td></tr></table></figure><p>修改rgb gamma参数如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;rgbgamma&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;enable&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;in_bit&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">10</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;out_bit&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">8</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;gammalut_nums&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">11</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;gammalut&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.3504950718773984</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.48243595264750255</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.57750428843709</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.6596458942714417</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.731034378464739</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.7925580792857235</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.8509817015104557</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.9029435754464383</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">0.9534255851019492</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-number">1.0</span><br>        <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h1 id="3-运行结果-其他ISP对比"><a href="#3-运行结果-其他ISP对比" class="headerlink" title="3. 运行结果&amp;其他ISP对比"></a>3. 运行结果&amp;其他ISP对比</h1><h2 id="3-1-Pipeline运行结果"><a href="#3-1-Pipeline运行结果" class="headerlink" title="3.1 Pipeline运行结果"></a>3.1 Pipeline运行结果</h2><table><thead><tr><th>备注</th><th>图像</th></tr></thead><tbody><tr><td>Raw</td><td><img src="/img/6_HDR_ISP/ISP/connan_raw14.png" alt="raw"></td></tr><tr><td>ISP Result(Ours)</td><td><img src="/img/6_HDR_ISP/ISP/isp_result.png" alt="ISP"></td></tr><tr><td>FastOpenISP Result</td><td><img src="/img/6_HDR_ISP/ISP/color_checker.png" alt="Fast ISP"></td></tr></tbody></table><hr><h2 id="3-2-与fastOpenIsp细节对比"><a href="#3-2-与fastOpenIsp细节对比" class="headerlink" title="3.2 与fastOpenIsp细节对比"></a>3.2 与fastOpenIsp细节对比</h2><table><thead><tr><th>ISP</th><th>图像1</th><th>图像2</th><th>备注</th></tr></thead><tbody><tr><td>Ours</td><td><img src="/img/6_HDR_ISP/ISP/our_detail.png" alt="Our Detail"></td><td><img src="/img/6_HDR_ISP/ISP/our_sharpen.png" alt="Our Detail"></td><td>细节与边界明显保留</td></tr><tr><td>Fast Open Isp</td><td><img src="/img/6_HDR_ISP/ISP/fast_detail.png" alt="Open Isp"></td><td><img src="/img/6_HDR_ISP/ISP/others_sharpen.png" alt="Open Isp"></td><td>细节丢失以及Color banding</td></tr></tbody></table><h2 id="3-3-后续工作"><a href="#3-3-后续工作" class="headerlink" title="3.3 后续工作"></a>3.3 后续工作</h2><ul><li>支持Lsc、Dpc、Rns、Cns等ISP模块;</li><li>GUI ISP调试工具编写，支持Gui调参。</li></ul><h2 id="3-4-项目支持"><a href="#3-4-项目支持" class="headerlink" title="3.4 项目支持"></a>3.4 项目支持</h2><ul><li>感谢您的支持，希望我的项目对您有帮助</li><li>项目初期，希望各位多多点赞以及随手点亮小星星</li><li>为了使本项目更快地扩展开发，我们需要您的充电</li></ul><p><img src="/img/6_HDR_ISP/AppreciationCode.png" alt="Appreciation Code"></p><h1 id="4-结束语"><a href="#4-结束语" class="headerlink" title="4 结束语"></a>4 结束语</h1><p>今天我们给大家介绍了开源HDR-ISP，希望对于入门的新人有一定的借鉴作用，同时希望我们的开源对于处于行业里面的你们有所帮助！</p><p>如果您对自动驾驶感兴趣，可以关注本公众号，当然有想了解的话题，也可以私信我，我们将对各位看官感兴趣的话题进行技术分享。</p><p>项目地址：<a href="https://github.com/JokerEyeAdas/HDR-ISP">https://github.com/JokerEyeAdas/HDR-ISP</a></p><p>项目GitHub快速传送门：<a href="https://github.com/JokerEyeAdas/HDR-ISP">HDR-ISP</a></p><hr><p><strong>如果您对ADAS感兴趣，欢迎关注我的公众号、知乎、CSDN等，同时发表文章中使用源码会在我的GitHub进行开源（网页About Me中有公众号、Github等信息）</strong></p><h1 id="参考仓库"><a href="#参考仓库" class="headerlink" title="参考仓库"></a>参考仓库</h1><p>感谢下述仓库以及仓库作者！！</p><table><thead><tr><th>序号</th><th>仓库</th><th>开发语言</th><th>备注</th></tr></thead><tbody><tr><td>0</td><td><a href="https://github.com/cruxopen/openISP">OpenISP</a></td><td>Python</td><td>image signal process in C style</td></tr><tr><td>1</td><td><a href="https://github.com/QiuJueqin/fast-openISP">fast-openIsp</a></td><td>Python</td><td>open isp 快速版本</td></tr><tr><td>2</td><td><a href="https://github.com/yuqing-liu-dut/ISPLab">ISP Lab</a></td><td>C++</td><td>C++版本开源ISP</td></tr><tr><td>3</td><td><a href="https://github.com/openasic-org/xkISP">xk-ISP</a></td><td>C++</td><td>复旦大学开源HLS ISP</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>ISP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HDR</tag>
      
      <tag>ISP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>iToF|一文了解iToF深度测距原理与芯片架构</title>
    <link href="/2023/08/02/5-Itof%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/"/>
    <url>/2023/08/02/5-Itof%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>之前我们在《<a href="https://mp.weixin.qq.com/s?__biz=MzkzNjQ0NDMyMg==&mid=2247483738&idx=1&sn=18a945bf534dcb61fa7b309b687a7e27&chksm=c29fe997f5e8608117e314616a05daf28751b6a2caa5426802132bdba93f366083f77d83b0db&token=1440854923&lang=zh_CN#rd">ADAS-激光雷原理概述</a>》中简要介绍了基于dToF的Lidar的组成、原理以及发展趋势等，但缺少了iToF的原理介绍，今天我们将基于Sony发表于2017年介绍其旗下IMX556同胞兄弟IMX528的iToF论文，一起来探讨iToF的基本原理、芯片架构等。想要论文的同学可以关注我的公众号“ADAS之眼”，后台回复IMX556获取。</p><p>另外，笔者同时下载了Sony激光雷达<code>IMX459</code>芯片的论文，后面我们再单独出一期文章，给大家介绍<code>IMX459</code>同其它家dToF芯片架构介绍与对比。<br>话不多少，先上索尼3D iToF IMX556的产品链接：<a href="https://www.sony-semicon.com/en/products/is/industry/tof.html">索尼官网IMX556芯片产品指标参数</a></p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>在过去的时间里面，CMOS图像传感器已经被广泛应用于手机、电脑等设备，图像传感器得以广泛的发展。同时传感器的工艺也得到了极大地发展，从前照式工艺到现在的背照式、图像逻辑层与感光层stack等工艺也越发成熟。</p><table><thead><tr><th>背照式vs前照式</th><th>半导体Stack工艺</th></tr></thead><tbody><tr><td><img src="/img/5_ITofPrinciple/backside-illuminated-cmos-vs-regular-cmos-1.gif" alt="前照vs背照"></td><td><img src="/img/5_ITofPrinciple/stack.png" alt="Stack"></td></tr></tbody></table><p>最近，各种应用中对深度传感的需求越来也多，如手势控制用户界面、3D建模、虚拟现实&#x2F;增强现实、机器人技术以及支持安全驾驶的车载摄像头。在这些需要识别和分类场景的应用中，传统一般使用2D图像处理算法，此方法适用于目标场景的用例控制得很好。例如，在工厂机器视觉中应用，场景和照明可以进行调整，同时基于固定场景优化图像处理算法，使目标对象可识别出高置信度。然而对于无法控制场景&#x2F;照明的应用，深度信息以及RGB 2D图像数据可以显著改善识别过程。例如深度信息在无光线可以识别人脸。因此，深度传感器将缓解2D图像数据处理约到的大部分困难。目前深度感知方案主要有以下方案：</p><p><img src="/img/5_ITofPrinciple/3D_Measure_Tech.png" alt="Technologies for 3D measure "></p><p>基于双目立体视觉的解决方案通常需要处理器进行大量数据的处理，而且立体视觉的性能依赖于足够的边缘信息来执行块匹配以获得视差图像。结构光解决方案提供更高的深度精度，但通常响应较慢，因为它通常需要发射不同的二进制pattern，然后采集反射的图像进行计算以生成深度图。</p><p>ToF（Time of Flight）是一种利用光飞行时间来测距的技术，通过发射光与物体发射光之间的延时来测距，如下所示：</p><p><img src="/img/5_ITofPrinciple/ToF.png" alt="ToF"></p><p>ToF分为direct Tof(dToF)以及indirect ToF(IToF)。dToF使用SPAD直接测量时间，而iToF通过连续波调制解调，通过计算相位差$Δφ$间接获取时间来达到测距的目的。然后距离则可以通过下述公式获得：</p><p>$$<br>d&#x3D;cΔt&#x2F;2&#x3D;cΔφ&#x2F;2w \<br>&#x3D;cΔφ&#x2F;4πf_{mod}<br>$$<br>其中：<br>$$<br>Δφ&#x3D;arctan((Q_{90}-Q_{270})&#x2F;(Q_{0}-Q_{180}))<br>$$</p><p>每个像素都有delay，$Δt$,它是从反射信号中的四个相位进行采样的信号计算而成，这个四个信号分别是$Q_0,Q_{90},Q_{180},Q_{270}$ 。$c$是光速，$f_{mod}$是发射信号的调制频率。</p><h1 id="2-iToF测量原理"><a href="#2-iToF测量原理" class="headerlink" title="2. iToF测量原理"></a>2. iToF测量原理</h1><h2 id="2-1-四相位iToF信号"><a href="#2-1-四相位iToF信号" class="headerlink" title="2.1 四相位iToF信号"></a>2.1 四相位iToF信号</h2><p>下图表示了四相位iToF的测量的基本原理(<strong>注意论文给的图中相位差符号是$α$,我们公式推导使用Δφ</strong>)：</p><p><img src="/img/5_ITofPrinciple/quad_chrip.png" alt="四相位"></p><p>这里需要注意，信号采样不是依次就完成了，因为单次反射光子数量较少，因此每帧曝光时间本质控制的是信号采集次数，一般对每个相位至少进行几千次采样。</p><h2 id="2-2-四相位iToF公式推导"><a href="#2-2-四相位iToF公式推导" class="headerlink" title="2.2 四相位iToF公式推导"></a>2.2 四相位iToF公式推导</h2><p>从图中可知，原始信号为正弦信号，反射信号在发射信号的基础上幅度、相位均有所变化，那么可有：</p><p>$$<br>Send_{signal}&#x3D;a*sin(wt)<br>$$<br>$$<br>Recv_{signal}&#x3D;Asin(wt+Δφ) +B<br>$$</p><p>由于$Q_0,Q_{90},Q_{180},Q_{270}$分别是在$0, π&#x2F;2, π, 3π&#x2F;2$的相位处完成的采样，因此有：</p><p>$$<br>Q_{0}&#x3D;Asin(0+Δφ) +B &#x3D;Asin(Δφ) + B<br>$$<br>$$<br>Q_{90}&#x3D;Asin(π&#x2F;2+Δφ) +B &#x3D; Acos(Δφ) + B<br>$$<br>$$<br>Q_{180}&#x3D;Asin(π+Δφ) +B &#x3D; -Asin(Δφ)+B<br>$$<br>$$<br>Q_{270}&#x3D;Asin(3π&#x2F;2+Δφ) +B &#x3D; -Acos(Δφ)+B<br>$$</p><p>那么可知：<br>$$<br>Δφ&#x3D;arctan((Q_{90}-Q_{270})&#x2F;(Q_{0}-Q_{180}))<br>$$<br>由于两两相减，此过程把环境光的干扰也同步去除了，因此测量精度较高。</p><p>同时其反射光亮度为：<br>$$<br>A&#x3D;√((Q_{90}-Q_{270})^2+(Q_{0}-Q_{180})^2) &#x2F;2<br>$$</p><h2 id="2-3-频谱混叠与多频调制"><a href="#2-3-频谱混叠与多频调制" class="headerlink" title="2.3 频谱混叠与多频调制"></a>2.3 频谱混叠与多频调制</h2><p>大家发现了一个问题没有，那就是相位差范围是$(0,2π)$，也就是说当距离超过$2π$则会有频谱混叠的现象，就是我们测量的相位0和相位2π是一样的，那么怎么解决呢？</p><p>答案是：<strong>多频调制</strong></p><p>我们知道，当前频率的混叠距离为：<br>$$<br>d_{amb}&#x3D;c&#x2F;2f<br>$$</p><p>其中$d_{amb}$即当前频率可以探测最大距离，如果我们想拓展测量距离，可以降低调制频率f，但这样会增大测量误差，因此为了测距的同时不降低精度，现在的tof都会采用多频技术。多频技术是增加一个或者多个频率调制波来混频，每个调制波测量都有不同的不明确的距离，但是真实距离就是多个频率调制波共同测量到的那个值，该位置对应频率也就是多个频率的最大公约数，称为 beat frequency 击打频率。击打频率一般会更低，也就扩展更长测量距离。双频技术如下图所示：</p><p><img src="/img/5_ITofPrinciple/dual_freq.png" alt="双拼调制"></p><h1 id="3-Pixel设计与sensor架构"><a href="#3-Pixel设计与sensor架构" class="headerlink" title="3 Pixel设计与sensor架构"></a>3 Pixel设计与sensor架构</h1><h2 id="3-1-电流辅助光子解调器CAPD"><a href="#3-1-电流辅助光子解调器CAPD" class="headerlink" title="3.1 电流辅助光子解调器CAPD"></a>3.1 电流辅助光子解调器CAPD</h2><p>为了实现高精度深度测量以及相位解调，现在的iToF的Pixel大部分都是采用基于背照式工艺制作的电流辅助光子解调器 (CAPD)。本质上CAPD是一个光子分流器，其原理如下所示： </p><p><img src="/img/5_ITofPrinciple/CAPD.png" alt="CAPD"></p><p>CAPD 允许每个像素的光电二极管内部存在交流电压，通过控制VmixA以及VmixB，产生漂移场，将电子分开并拉至交替的探测器结。在下面的简化示例中，调制光从 VCSEL（垂直腔表面发射激光器）二极管发射。光被反射回像素光电二极管，在那里被转换成电子并在交替的检测器结之间分配。</p><p><img src="/img/5_ITofPrinciple/Sony-DepthSense-Time-of-Flight-Sensor-1.gif" alt="CAPD控制光子流通"></p><h2 id="3-2-Pixel工艺"><a href="#3-2-Pixel工艺" class="headerlink" title="3.2 Pixel工艺"></a>3.2 Pixel工艺</h2><p>论文中给出了当前工作相对于传统的工艺变化，如下所示：</p><p><img src="/img/5_ITofPrinciple/pixel_gy.png" alt="Pixel工艺"></p><p>可以看出，相对于之前：</p><ul><li>硅片的厚度减少</li><li>检测的pn结以及偏执电压输入改为硅片底部</li><li>偏置电压由1.8V修改为1.2V</li></ul><p>最终结果也很直观，电子的转移速度得到有效地提升。</p><h2 id="3-3-Sensor整体架构"><a href="#3-3-Sensor整体架构" class="headerlink" title="3.3 Sensor整体架构"></a>3.3 Sensor整体架构</h2><p>论文中给出iToF的整体架构如下所示：</p><p><img src="/img/5_ITofPrinciple/arch.png" alt="Sensor架构"></p><p>这里可以发现，2D以及3D图像传感器的框架相似，基本模块类似，如：</p><ul><li>参考电压</li><li>行列选择器</li><li>ADC模数转换模块</li><li>MIPI接口</li></ul><p>不同的是，iToF<strong>Pixel架构与CIS不同且多了信号的调制解调。</strong>对CIS感兴趣的同学可以看我之前关于sony以及onsmei车载CIS传感器的介绍,《<a href="https://mp.weixin.qq.com/s?__biz=MzkzNjQ0NDMyMg==&mid=2247484132&idx=1&sn=98066f0d36789906f5563219d1e14fb1&chksm=c29fea29f5e8633fb00e30c3eb096d1648e37c74310bf371e764f4d5263d56752e965502654a&token=1440854923&lang=zh_CN#rd">ADAS-一文看懂索尼车载CIS传感器之SubPixel-HDR技术</a>》《<a href="https://mp.weixin.qq.com/s?__biz=MzkzNjQ0NDMyMg==&mid=2247484148&idx=1&sn=4f2fc795852d06dd1e85c890b30b6165&chksm=c29fea39f5e8632fb6e27f97b6cdb56fab1776f61a456a1adc84de5ed3fb3a9877a3eccdf400&token=1440854923&lang=zh_CN#rd">ADAS-安森美车载AR0821两帧150dB是如何炼成的？</a>》。</p><h2 id="3-4-采样时序与帧结构"><a href="#3-4-采样时序与帧结构" class="headerlink" title="3.4 采样时序与帧结构"></a>3.4 采样时序与帧结构</h2><p>通过CPAD通过控制偏执电压VimxA以及VimxB，便可在不同时间采集不同相位数据。Sensor的工作时序如下所示：</p><p><img src="/img/5_ITofPrinciple/frame_timing.png" alt="frame timing"></p><p>可以看出，整体工作流程和CIS传感器类似，都是分三个阶段，复位、曝光、AD采样，只是这里的曝光是Sensor主动发射光源，然后采集反射信号。</p><p>另外需要注意的是，这四个相位的数据是分开时间点采集的，Sensor的相位采样时序如下所示：</p><p><img src="/img/5_ITofPrinciple/smaple_timing.png" alt="采样时序"></p><p>因此，最终输出到后端进行处理的raw数据结构如下所示：</p><p><img src="/img/5_ITofPrinciple/frame.png" alt="Frame Timing"></p><h2 id="3-5-测量效果"><a href="#3-5-测量效果" class="headerlink" title="3.5 测量效果"></a>3.5 测量效果</h2><p>论文最后给出了当前工作与传统芯片的效果对比，如下所示：</p><p><img src="/img/5_ITofPrinciple/result.png" alt="测量效果对比"></p><p>可以看出，当前sensor的分辨率、噪声控制以及平滑度都有较大的的提升。</p><h1 id="4-结束语"><a href="#4-结束语" class="headerlink" title="4 结束语"></a>4 结束语</h1><p>今天我们给大家介绍了Sony的基于3D-iToF芯片论文，讲解了四相位法iToF的基本测量原理、公式推导以及芯片pixel原理、架构等。希望今天的介绍以及科普对您有所帮助。</p><p>如果您对今天的内容感兴趣，请公众号后台私信我《<code>Sony iToF</code>》，获取论文DOI。</p><hr><p><strong>如果您对ADAS感兴趣，欢迎关注我的公众号、知乎、CSDN等，同时发表文章中使用源码会在我的GitHub进行开源<code>（网页About Me中有公众号、Github等信息）</code></strong></p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[0] 320 × 240 Back-Illuminated 10-µm CAPD Pixels for High-Speed Modulation Time-of-Flight CMOS Image Sensor</p><p>[1] 3D ToF 三维场景距离（景深）测量系统简介</p>]]></content>
    
    
    <categories>
      
      <category>iToF</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ADAS</tag>
      
      <tag>Lidar</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ADAS-EE|自动驾驶汽车E/E拓扑架构与软件功能框架</title>
    <link href="/2023/07/26/3.%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E6%B1%BD%E8%BD%A6%E7%94%B5%E6%B0%94%E4%B8%8E%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0/"/>
    <url>/2023/07/26/3.%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E6%B1%BD%E8%BD%A6%E7%94%B5%E6%B0%94%E4%B8%8E%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><blockquote><p><strong>之前在公众号中我们对自动驾驶常见传感器的原理进行了讲解，如《<a href="https://mp.weixin.qq.com/s?__biz=MzkzNjQ0NDMyMg==&mid=2247483674&idx=1&sn=25f2ec8a22e3d94422f98410ddfe3b34&chksm=c29fe9d7f5e860c1e0439f6039b638314bc88e13be47e08ec3a188b85077f8e3a7402e3e2bed&token=1080996952&lang=zh_CN#rd">可见光相机</a>》《<a href="https://mp.weixin.qq.com/s?__biz=MzkzNjQ0NDMyMg==&mid=2247483842&idx=1&sn=84a9c03ed5d59407185f63cb8b8c0d80&chksm=c29fe90ff5e86019c4b968c2ed4d40b4062fd1310bf89071e3fe0b7f557d83999fa3def9d517&token=1080996952&lang=zh_CN#rd">IMU惯导传感器</a>》《<a href="https://mp.weixin.qq.com/s?__biz=MzkzNjQ0NDMyMg==&mid=2247483820&idx=1&sn=dab55af7a501aa931ee783b4a2f2d1db&chksm=c29fe961f5e860775da0de7b7f91f073e5044d825868f577aa0e2105b9355d4d00820309f364&token=1080996952&lang=zh_CN#rd">GPS传感器原理</a>》《<a href="https://mp.weixin.qq.com/s?__biz=MzkzNjQ0NDMyMg==&mid=2247484260&idx=1&sn=cc3da360b8e8dbc43e35fcb263583f9d&chksm=c29feba9f5e862bffb93666df7b52f1f11f5b36293f834e30f23214cb3894e0a992f036751b9&token=1080996952&lang=zh_CN#rd">毫米波雷达原理</a>》以及《<a href="https://mp.weixin.qq.com/s?__biz=MzkzNjQ0NDMyMg==&mid=2247483738&idx=1&sn=18a945bf534dcb61fa7b309b687a7e27&chksm=c29fe997f5e8608117e314616a05daf28751b6a2caa5426802132bdba93f366083f77d83b0db&token=1080996952&lang=zh_CN#rd">激光雷达原理</a>》。今天我们将结合TI自动驾驶部门专家发表的相关的论文，讲解现代自动驾驶汽车车身电气架构以及ADAS辅助驾驶软件的功能架构。(本文首发于博客&amp;公众号-“<a href="https://jokereyeadas.github.io/">ADAS之眼</a>“其他平台同步更新)</strong></p></blockquote><p>目前汽车辅助驾驶还是处于L2+阶段，L3以及L3以上的高阶辅助驾驶也是各大公司在积极研究的项目，并且高阶辅助驾驶也是下一代系列汽车市场的发展领域。</p><p>本文介绍以ADAS&#x2F;AD域为重点的典型车辆电子拓扑，其具有多个内部&#x2F;内部连接选项。在ADAS&#x2F;AD域，各种E&#x2F;E电气电子系统架构被拓扑多个ECU分区。本文分析了两个ADAS&#x2F;AD域的系统拓扑示例，其中Topology-I使用了基于传统ECU的增量方法，而拓扑II实现了成本优化的解决方案。</p><p>本文还解释了自动驾驶功能的划分，例如高速公路驾驶、自动泊车。这涉及到拆分在给定拓扑中跨多个ECU的自动化感知（相机、雷达和激光雷达）、定位、融合、驾驶策略、运动规划和控制等功能。</p><p>希望今天的科普可以使您对于ADAS汽车有着更深入的了解与认知！</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>汽车自动驾驶功能，如高速公路驾驶和停车辅助系统，越来越多地部署在中高端汽车中。随着自动驾驶汽车的发展，汽车车辆具有越来越复杂的电气和电子（E&#x2F;E）拓扑结构以解决汽车复杂的功能，典型的E&#x2F;E拓扑架构如下图所示:</p><p><img src="/img/3_AdasCarArch/EE_Topology.png" alt="汽车E/E拓扑"></p><p>该电气电子拓扑的核心是各种ECU，它主要由MCU或者MPU组成，可以选择进行组合以实现给定的功能。为了给车辆提供可扩展、强健以及可维护的解决方案，汽车的E&#x2F;E拓扑结构通常由多个域组成，其中每个域控制一组功能。在每个域中，都有多个ECU，每个ECU控制一个功能或一组功能。</p><p>E&#x2F;E拓扑架构中常用的域如下：</p><ul><li><strong>底盘和安全领域</strong>：控制转向的ECU，汽车油门控制；</li><li><strong>电源控制域</strong>：用于控制发动机和电池等相关功能的ECU；</li><li><strong>身体电子领域</strong>：控制车窗、空调、后视镜以及中央锁定等功能的ECU；</li><li><strong>信息娱乐领域</strong>：控制娱乐显示的ECU，如AR-HUD、电子后视镜、无线电、导航等；</li><li><strong>ADAS&#x2F;AD域</strong>：传感器（摄像头，雷达、激光雷达）数据接入、感知处理、规划决策等；</li><li><strong>连接&#x2F;远程通信领域</strong>：包括调制解调器V2X、移动、蜂窝网络等以提供汽车与外部连接能力。</li></ul><p>每个域内的ECU使用多个连接电缆和协议，例如基于CAN、车载以太网的的通信。中间网关为不同域之间通信的桥梁，所有控制域均连接到中央网关，不同域之间的通信通过中央网关完成。</p><h1 id="ADAS-AD域"><a href="#ADAS-AD域" class="headerlink" title="ADAS&#x2F;AD域"></a>ADAS&#x2F;AD域</h1><h2 id="ADAS-AD-功能框架"><a href="#ADAS-AD-功能框架" class="headerlink" title="ADAS&#x2F;AD 功能框架"></a>ADAS&#x2F;AD 功能框架</h2><p>在汽车众多的控制域中，ADAS&#x2F;AD域实现了高速公路驾驶、城区自动驾驶以及多个自动泊车等功能（L2-L5)。下图显示了实现这些功能的软硬件框图：</p><p><img src="/img/3_AdasCarArch/Adas_Func_Block.png" alt="ADAS功能框架"></p><p>自动驾驶的关键块是感知、定位、融合、驾驶策略、路径规划和控制。各个关键模块功能分别如下：</p><ul><li><strong>感知</strong>：利用摄像头、毫米波雷达、激光雷达等传感器用于收集汽车周围的环境信息；</li><li><strong>融合</strong>：结合多传感器特性完成外界信息的融合以及提取；</li><li><strong>定位</strong>：结合相机、IMU惯导、GPS全球定位以及高精地图信息来完成汽车的定位；</li><li><strong>路径规划</strong>：结合V2X以及融合后的感知、定位信息，完成汽车的路径规划；</li><li><strong>运动控制</strong>：结合路径规划信息，完成对汽车的运动控制</li></ul><p>其中，感知以及多传感器融合是后续路径规划以及控制的前提，因此感知融合的结果的准确性对于汽车进行控制尤为重要。</p><h2 id="多传感器融合"><a href="#多传感器融合" class="headerlink" title="多传感器融合"></a>多传感器融合</h2><p>这里结合另一篇论文中camera结合毫米波雷达进行融合为例进行说明，简要说明多传感器在汽车高阶自动驾驶中感知的应用。</p><p>首先，我们要确定一点，那就是<code>&quot;没有完美的传感器&quot;</code>。不同传感器由于机制的不同，因此针对不同感知任务的性能不同。典型Camera以及毫米波雷达针对不同感知任务的特性如下所示：</p><p><img src="/img/3_AdasCarArch/camera_radar.png" alt="Camera vs Radar"></p><p>可知的是，Camera受天气影响较大，且对于物体的速度、距离测量效果较差，而毫米波雷达恰恰又可以弥补Camera的缺陷。同样的，Camera也可以弥补雷达无法对物体进行分类的的缺陷。因此，不同的传感器进行融合结果更加准确，同时也符合汽车功能安全的需求。</p><p>典型的Camera与Radar融合框架如下：</p><p><img src="/img/3_AdasCarArch/fustion.png" alt="Camera Radar Fusion"></p><p>可以看出，Radar结合Camera融合后，物体的类别、角度、速度、距离等信息均可以得到，给后续的导航、路径规划提供了丰富的信息。</p><h2 id="ADAS-AD-ECU拓扑示例"><a href="#ADAS-AD-ECU拓扑示例" class="headerlink" title="ADAS&#x2F;AD ECU拓扑示例"></a>ADAS&#x2F;AD ECU拓扑示例</h2><h3 id="拓扑1"><a href="#拓扑1" class="headerlink" title="拓扑1"></a>拓扑1</h3><p>Demo拓扑1的结构建立在传统ADAS功能的基础上，例如基于前视相机以及中央雷达的LKA（车道保持辅助）、盲点检测（BSD）、前向碰撞警告（FCW）等。这种拓扑的结构如下所示：<br><img src="/img/3_AdasCarArch/TopologyI.png" alt="Topology I"></p><p>在该拓扑中，检测的对象数据（行人、车辆以及车道线等）通常是使用单独的ECU来计算的。数据计算完成后传递到中央ECU进行融合。在该拓扑结构中，带宽要求在ADAS&#x2F;AD域中是较低的，因此可以使用低速接口处理，例如CAN-FD等。中央融合ECU提供功能安全保障，使用提供冗余的两个芯片和ASIL-D MCU或者MPU。融合后的数据可以通过网关和控制域ECU进行通信，完成车辆的偏离车道控制或者防行人碰撞等功能。</p><h3 id="拓扑2"><a href="#拓扑2" class="headerlink" title="拓扑2"></a>拓扑2</h3><p>这种拓扑结构从头开始构建的新架构，旨在优化整体性能的驾驶功能，如下图所示：</p><p><img src="/img/3_AdasCarArch/TopologyII.png" alt="Topology II"></p><p>在这种拓扑结构中，预融合ECU（称为卫星ECU）用于在前方进行感知摄像头、雷达和激光雷达以及环视相机。处理后的前方和周围的融合信息被传递到中央融合ECU进行最终融合。在ADAS&#x2F;AD域中的带宽要求主要看融合数据的精细度。中央fusion ECU使用提供冗余的两个芯片和ASIL-D MCU或者MPU。中心的fusion ECU还执行定位、驾驶策略、运动规划等功能。执行器的计算控制命令通过使用域的中央网关发送到汽车控制域控制器。这种拓扑结构的优点是操作灵活，数据融合的性能有所提升。</p><h1 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h1><p>今天我们介绍了现在自动驾驶汽车的电子电气整体框架、ADAS域功能框架以及ADAS域可能使用的两种拓扑框架，当然随着科技的发展，更好更优的架构不断出现，不断进化着我们的自动驾驶汽车。</p><p>希望我们的介绍可以使您对于自动驾驶汽车框架有着更好地理解！如果您对今天的内容感兴趣，请公众号后台私信我《<code>ADAS E/E 拓扑</code>》，获取论文DOI。</p><hr><p><strong>如果您对ADAS感兴趣，欢迎关注我的公众号、知乎、CSDN等，同时发表文章中使用源码会在我的GitHub进行开源<code>（网页About Me中有公众号、Github等信息）</code></strong></p>]]></content>
    
    
    <categories>
      
      <category>ADAS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ADAS</tag>
      
      <tag>E/E</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ADAS-Radar|一文入门汽车毫米波雷达基本原理</title>
    <link href="/2023/07/20/2.%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86/"/>
    <url>/2023/07/20/2.%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p><strong>刚接触毫米波雷达的时候并不清楚它是如何用2Tx天线加4Rx天线就能做到多目标检测，随着学习的不断深入，才恍然大悟，科学真的很奇妙！信号与系统老师诚不欺我！</strong></p><p>随着现代社会对于安全驾驶和智能交通的不断追求，汽车技术正朝着前所未有的高度发展。其中，毫米波雷达技术作为一种先进的传感器技术，正在引领着汽车领域的革命性变革。毫米波雷达以其高精度、可靠性和适应性，在自动驾驶、碰撞预警、自适应巡航控制等关键领域发挥着不可或缺的作用，将汽车的安全性、便捷性和智能化水平推向新的高度。</p><p><img src="/img/2_RadarPrinciple/radar_car.png" alt="Radar in Car"></p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.Introduction"></a>1.Introduction</h1><p>毫米波雷达作为一种主要的感知技术，在汽车安全系统中扮演着重要的角色。它利用毫米波频段的电磁波来感知周围环境，并通过测量反射回来的信号来检测和跟踪其他车辆、行人、障碍物以及道路状况。</p><p>与传统的红外传感器和激光雷达相比，毫米波雷达具有独特的优势。它能够利用毫米波频段的电磁波，穿透恶劣天气条件，如雨、雪和雾，从而实现在复杂环境下的可靠探测。</p><p>本文将重点介绍汽车毫米波雷达的原理和工作方式，我们将简要解释毫米波雷达的基本原理，包括其工作频段和探测原理。</p><h1 id="2-FMCW雷达介绍"><a href="#2-FMCW雷达介绍" class="headerlink" title="2.FMCW雷达介绍"></a>2.FMCW雷达介绍</h1><h2 id="2-1-基本概念"><a href="#2-1-基本概念" class="headerlink" title="2.1 基本概念"></a>2.1 基本概念</h2><p>目前市面上毫米波雷达基于连续波调频 (FMCW)技术，因此下面我们将以FMCW雷达指代毫米波雷达。顾名思义，FMCW 雷达连续发射调频信号，以测量距离以及角度和速度。FMCW雷达通过反射信号的相位以及频率来定位、测速、测速等，这与激光雷达周期性发射短脉冲然后通过直接测量返回时间的原理不同。（<strong>关于激光雷达原理可以看我公众号另外一篇文章</strong> <a href="https://mp.weixin.qq.com/s?__biz=MzkzNjQ0NDMyMg==&mid=2247483738&idx=1&sn=18a945bf534dcb61fa7b309b687a7e27&chksm=c29fe997f5e8608117e314616a05daf28751b6a2caa5426802132bdba93f366083f77d83b0db&token=2025311329&lang=zh_CN#rd">激光雷达基本原理详解</a>）</p><p>FMCW雷达系统所用信号的频率随时间变化呈线性升高。这种类型的信号也称为线性调频脉冲。 下图以幅度（振幅）相对时间的（A-t）函数，显示了线性调频脉冲信号表示。<br><img src="/img/2_RadarPrinciple/fmcw_at.png" alt="FMCW t-A曲线"><br>以纵轴为频率，横轴为时间，则其（f-t）图像表示如下所示：<br><img src="/img/2_RadarPrinciple/fmcw_tf.png" alt="FMCW雷达f-t图像"></p><h2 id="2-2-基本框架"><a href="#2-2-基本框架" class="headerlink" title="2.2 基本框架"></a>2.2 基本框架</h2><p>FMCW雷达基本框架如下所示：</p><p><img src="/img/2_RadarPrinciple/base_arch.png" alt="FMCW雷达基本架构"></p><p>可以看出，FMCW雷达由下述基础组件构成：</p><ul><li>发送天线(Tx Antenna)&amp;接收天线(Rx Antenna)</li><li>混频器(Mixer)</li><li>时钟源(晶振)</li><li>ADC &amp; DSP</li></ul><h2 id="2-3-工作流程"><a href="#2-3-工作流程" class="headerlink" title="2.3 工作流程"></a>2.3 工作流程</h2><p>雷达工作流程如下：</p><ul><li>合成器生成一个线性调频脉冲；</li><li>该线性调频脉冲由发射天线（TX 天线）发射；</li><li>物体对该线性调频脉冲的反射生成一个由接收天线（RX 天线）捕捉的反射线性调频脉冲；</li><li>“混频器”将 RX 和 TX 信号合并到一起，生成一个中频 (IF) 信号。</li></ul><p>其中：</p><p><strong>混频器是一个电子组件，将两个信号合并到一起生成一个具有新频率的新信号。</strong></p><p>其解释如下：</p><p>对于两个正弦函数信号$x_1$和$x_2$如下：</p><p>$$<br>x1&#x3D;sin(w_1t + φ_1) \<br>x2&#x3D;sin(w_2t + φ_2)<br>$$</p><p>对于输出$x_{out}$有一个瞬时频率，等于两个输入正弦函数的瞬时频率之差。输出$x_{out}$的相位等于两个输入信号的相位之差，如下：<br>$$<br>x_{out}&#x3D;sin((w_1 - w_2)t + (φ_1 - φ_2))<br>$$</p><h1 id="3-测距原理"><a href="#3-测距原理" class="headerlink" title="3.测距原理"></a>3.测距原理</h1><h2 id="3-1-雷达信号"><a href="#3-1-雷达信号" class="headerlink" title="3.1 雷达信号"></a>3.1 雷达信号</h2><p>以单个物体检测为例，使用时间对频率（f-t）图像对于 Tx、Rx 以及混频的 IF 信号的表示如下所示：</p><p><a id="FMCW测距原理图像">FMCW测距原理信号图像</a><br><img src="/img/2_RadarPrinciple/radar_inout.png" alt="输出输入频率图像"></p><p>可以看出混频信号IF是一个频率固定的正弦信号$Asin(2πf_ot+φ_0)$。</p><h2 id="3-2-距离计算"><a href="#3-2-距离计算" class="headerlink" title="3.2 距离计算"></a>3.2 距离计算</h2><p>假设物体的距离为$d$，那么 Rx 与 Tx 之间的延时 $τ$ 计算如下：</p><p>$$<br>τ &#x3D; 2d &#x2F; c<br>$$</p><p>其中：$d$ 是距离，$c$ 是光速</p><p><strong>注意：</strong> $d$ 是待测目标距离，而$τ$是电磁波的飞行时间，由于飞行时间极短，因此如果直接对$τ$使用硬件测量成本极高（参考激光雷达）。</p><p><strong>所以：</strong> 这里换一个方式，我们通过FFT反推信号的频率和相位，转换得到速度、距离等信息，推导过程如下：</p><p>高中三角函数学过，旋转角频率$w$和频率$f$之间关系如下：</p><p>$$<br>w &#x3D; 2πf<br>$$</p><p>那么对于 Rx 以及 Tx 混合得到 IF 信号的初始相位有：</p><p>$$<br>φ_0 &#x3D; w_c * τ &#x3D; 2πf_c τ<br>$$</p><p>其中：$f_c$是雷达的Tx信号的初始频率</p><p>由于：</p><p>$$<br>τ &#x3D; 2d &#x2F; c<br>$$</p><p>因此:</p><p>$$<br>φ_0 &#x3D; 2πf_c2d &#x2F; c &#x3D; 4πf_cd &#x2F; c \<br>&#x3D; 4πd&#x2F;λ<br>$$</p><p>其中，$λ$为初始信号波长($c&#x3D;f_cλ$)</p><p>其次，根据<a href="#FMCW%E6%B5%8B%E8%B7%9D%E5%8E%9F%E7%90%86%E5%9B%BE%E5%83%8F">FMCW测距原理图像</a>，可知混频 IF 信号其频率$f_o$为</p><p>$$<br>f_o &#x3D; 2Sd&#x2F;c<br>$$</p><p>其中：$S$为FMCW频率变化率，单位为Mhz&#x2F;s</p><p>那么，IF 信号可以表示如下：</p><p>$$<br>IF &#x3D; Asin(2πf_ot+φ_0)<br>$$</p><p>其中：$f_o &#x3D; 2Sd&#x2F;c$，$φ_0 &#x3D; 4πd &#x2F; λ$</p><p>到这里，我们便可以知道，对于一个反射物体，我们对 IF 信号做FFT，可以知道其频率$f$以及相位$φ$，那么其距离为：</p><p>$$<br>d &#x3D; f_oc &#x2F; 2S &#x3D; φ_0c&#x2F;4πf_c<br>$$</p><p>一般计算时我们选择频率计算即可。</p><h2 id="3-3-多目标距离计算"><a href="#3-3-多目标距离计算" class="headerlink" title="3.3 多目标距离计算"></a>3.3 多目标距离计算</h2><p>对于多目标物体，IF混频信号则由多反射目标距离不同，那么反射回来图像则如下所示：</p><p><img src="/img/2_RadarPrinciple/mult-fft.png" alt="多目标反射信号"><br>可以看出，多目标反射则对应多个Rx信号，其频率与相位均不相同。对IF信号做完FFT之后可以得到多个主干频率如下：</p><p><img src="/img/2_RadarPrinciple/mult_obj.png" alt="多目标FFT"></p><p>通过$d &#x3D; f_oc &#x2F; 2S$ 则可以分别计算出这三个物体的距离了。</p><h2 id="3-4-距离分辨率计算"><a href="#3-4-距离分辨率计算" class="headerlink" title="3.4 距离分辨率计算"></a>3.4 距离分辨率计算</h2><p>距离分辨率是辨别两个或更多物体的能力。当两个物体靠近到某个位置时，雷达系统将不再能够将二者区分开物体。傅里叶变换理论指出，通过延长 IF信号，可以提高分辨率。</p><p>但要延长 IF 信号，还必须按比例增加带宽。延长的IF 信号会产生一个有两个分离峰值的 IF 谱。</p><p>傅里叶变换理论还指出，观测窗口 (T) 可以分辨间隔超过 1&#x2F;THz 的频率分量。这意味着只要频率差满足下面公式中给出的关系，就可以分辨两个 IF 单音信号。</p><p>$$<br>Δf&gt;1&#x2F;T_c<br>$$</p><p>其中$T_c$是观测时间长度，即做FFT信号时间长度。</p><p>而由于：</p><p>$$<br>Δf&#x3D;2SΔd&#x2F;c<br>$$</p><p>则有</p><p>$$<br>Δd&gt;c&#x2F;2ST_c&#x3D;c&#x2F;2B (B&#x3D;ST_c)<br>$$</p><p>因此距离分辨率有：</p><p>$$<br>Δd_{res}&#x3D;c&#x2F;2B<br>$$</p><p>因此，对于带宽为 Ghz 的FMCW雷达，大概为cm级别的分辨率，例如带宽$B&#x3D;4Ghz$线性调频脉冲带宽的的雷达距离分辨率为3.75cm：</p><p>$$<br>Δd_{res}&#x3D;c&#x2F;2B&#x3D;0.0375m<br>$$</p><p>好了到这里距离已经计算出来了，那么速度、角度是怎么计算出来的呢？<strong>请继续往下看！！！</strong></p><h1 id="4-测速原理"><a href="#4-测速原理" class="headerlink" title="4.测速原理"></a>4.测速原理</h1><h2 id="4-1-Radar测速信号"><a href="#4-1-Radar测速信号" class="headerlink" title="4.1 Radar测速信号"></a>4.1 Radar测速信号</h2><p>为了测量速度， FMCW 雷达会发射两个间隔 $T_c$ 的线性调频脉冲。每个反射的线性调频脉冲通过 FFT加以处理，以便检测物体的距离，这个FFT称之为距离FFT。对应于每个线性调频脉冲的距离 FFT 将在同一位置出现峰值，但相位不同。该测得的相位差对应于速度为 $vT_c$ 的物体的移动</p><p><img src="/img/2_RadarPrinciple/radar_meature_spd.png" alt="双线性脉冲速度测量"></p><p>通过相位差公式$φ_0 &#x3D; 4πd &#x2F; λ$我们可以知：</p><p>$$<br>Δφ&#x3D;4πΔd&#x2F;λ&#x3D;4πvT_c&#x2F;λ<br>$$</p><p>则有：</p><p>$$<br>v&#x3D;Δφλ&#x2F;4πT_c<br>$$</p><p>由于速度测量基于相位差，因为相位存在周期性为$(-π，π)$，因此会存在模糊性或者周期性。这种测量仅在 $|Δφ| &lt; π$ 时具有非模糊性。</p><p>故可知 <strong>当$|Δφ|&#x3D; π$，雷达最大可测量的速度为：</strong></p><p>$$<br>v_{max}&#x3D;λ&#x2F;4T_c<br>$$</p><h2 id="4-2-同一位置不同物体速度测算"><a href="#4-2-同一位置不同物体速度测算" class="headerlink" title="4.2 同一位置不同物体速度测算"></a>4.2 同一位置不同物体速度测算</h2><p>如果速度不同的多个移动物体在测量时与雷达的距离相同，则双线性调频脉冲速度测量方法不起作用。这些物体由于与雷达的距离相同，因而会生成IF 频率完全相同的反射线性调频脉冲。因此，距离FFT 会产生单个峰值，该峰值表示来自所有这些距离相同的物体的合并信号。简单的相位比较技术将不起作用。</p><p>在这种情况下，为了测量速度，雷达系统必须发射两个以上的线性调频脉冲。它发射一组 N 个等间隔线性调频脉冲。这组线性调频脉冲称为线性调频脉冲帧。</p><p>下图显示了一个线性调频脉冲帧随时间变化的频率：</p><p><img src="/img/2_RadarPrinciple/linear_freq.png" alt="线性调频脉冲"></p><p>距离 FFT 处理反射的一组线性调频脉冲，从而产生一组 N 个位置完全相同的峰值，但每个峰值都有一个不同的相位，包含来自这两个物体的相位成分（来自各个物体的单独相位成分由下图中的红色和蓝色相量表示）。</p><p><img src="/img/2_RadarPrinciple/range_fft.png" alt="距离FFT产生的N个向量"></p><p>这个里  $v_1$ 和 $v_2$  通过多普勒FFT则可以获取，即对n组信号的每个信号单独做FFT，具体可以参考下图：</p><p><img src="/img/2_RadarPrinciple/drppler_fft.png" alt="多普勒FFT"></p><p>通过多普勒FFT，便可以区分出两个不同速度物体：</p><p><img src="/img/2_RadarPrinciple/droppler_fft_spd.png" alt="多普勒FFT区分两个物体"></p><p>其中  $w_1$ 和 $w_2$  对应于各个物体连续线性调频脉冲之间的相位差，则两个物体的速度可以得到如下：</p><p>$$<br>v_1&#x3D;w_1λ&#x2F;4πT_c \<br>v_2&#x3D;w_2λ&#x2F;4πT_c<br>$$</p><h2 id="4-3-速度分辨率"><a href="#4-3-速度分辨率" class="headerlink" title="4.3 速度分辨率"></a>4.3 速度分辨率</h2><p>离散傅里叶变换的理论指出，两个离散频率 $w_1$ 和 $w_2$ 在 $Δw &#x3D; w_2 – w1 &gt; 2π &#x2F; N$ 个弧度&#x2F;样本时，是可以分辨的。</p><p>由于 $Δw$ 是由 $Δφ&#x3D;4πvT_c&#x2F;λ$定义的，因而当帧周期为 $Tf &#x3D; NT_c$ 时，可通过数学方法推导出速度分辨率：</p><p>$$<br>v&gt;v_{res}&#x3D;λ&#x2F;2T_f<br>$$</p><p>可知，雷达的速度分辨率与帧时间 $T_f$ 成反比</p><h1 id="5-角度测量"><a href="#5-角度测量" class="headerlink" title="5 角度测量"></a>5 角度测量</h1><h2 id="5-1-角度测量条件"><a href="#5-1-角度测量条件" class="headerlink" title="5.1 角度测量条件"></a>5.1 角度测量条件</h2><p>FMCW 雷达系统可以使用水平面估算反射信号的角度，该角度也称为到达角 (AoA)，如下图所示：</p><p><img src="/img/2_RadarPrinciple/radar_aoa.png" alt="Radar到达角"></p><p>需要注意的是雷达估算角度至少需要两个 Rx 天线，如下图所示：</p><p><img src="/img/2_RadarPrinciple/aor_tx_rx.png" alt="使用2Rx天线估计角度"></p><h2 id="5-2-角度测量推导"><a href="#5-2-角度测量推导" class="headerlink" title="5.2 角度测量推导"></a>5.2 角度测量推导</h2><p>我们知道，对于同一个物体，两个接受天线接受的相位差为：</p><p>$$<br>Δφ&#x3D;wΔt<br>$$</p><p>其中，$w&#x3D;2πf_c$, $Δt&#x3D;dsin(θ)&#x2F;c$</p><p>因此：</p><p>$$<br>Δφ&#x3D;2πf_cdsin(θ)&#x2F;c \<br> &#x3D; 2πdsin(θ)&#x2F;λ<br>$$</p><p>因此，角度可以通反三角函数得到：</p><p>$$<br> θ &#x3D; sin^{-1}(Δφλ&#x2F;2πd)<br>$$</p><p>注意，$Δφ$ 取决于 $sin(θ)$，这被称为非线性依赖关系。</p><p>$sin(θ)$仅在$θ$的值很小时，才是线性函数的近似值： $sin(θ)&#x3D;θ$。因此，估算准确度取决于 AoA，且在 $θ$ 的值很小时更准确，如下图所示：<br><img src="/img/2_RadarPrinciple/aoa_acc.png" alt="AoA精度"></p><p>与速度获取计算方式相似，想计算物体的角度偏差，需要计算不同接受天线之间的相位差，好了第三个角度 FFT 来了，还是参考图像如下：</p><p><img src="/img/2_RadarPrinciple/drppler_fft.png" alt="多普勒FFT"></p><h2 id="5-3-最大视场角"><a href="#5-3-最大视场角" class="headerlink" title="5.3 最大视场角"></a>5.3 最大视场角</h2><p>雷达的最大角视场由雷达可以估算的最大 AoA 来界定，如下：<br><img src="/img/2_RadarPrinciple/aoa_max.png" alt="最大AoA"></p><p>由于角度的精准测量受制于 $|Δw| &lt; 180°$，对应关系有</p><p>$$<br> 2πdsin(θ)&#x2F;λ &lt; π<br>$$</p><p>因此，角度最大为：</p><p>$$<br> θ_{max} &#x3D; sin^{-1}(λ&#x2F;2d)<br>$$</p><p>可知：两个天线之间的间隔 $d &#x3D; λ&#x2F;2$ 会导致 ±90°的最大角视场</p><h1 id="6-总结与效果"><a href="#6-总结与效果" class="headerlink" title="6. 总结与效果"></a>6. 总结与效果</h1><p>不同频率的雷达测量距离不同、最大探测角度也不同。目前Radar最基础的算法就是FFT，基于距离FFT、速度FFT以及角度FFT获取物体的运动信息，最终得到雷达图像。</p><p>Radar的典型效果如下所示：</p><p><img src="/img/2_RadarPrinciple/radar_result.png" alt="测量效果"></p><p>可以看出，目前3D Radar探测效果为一个平面数据，只有速度v、距离d以及角度θ信息，缺少了高度h信息，而这个在后续的4D Radar中进行了优化，这个我们后面再讲。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] 毫米波雷达传感器基础知识</p><p>[2] MIMO Radar</p><hr><p><strong>如果您对ADAS感兴趣，欢迎关注我的公众号、知乎、CSDN等，同时发表文章中使用源码会在我的GitHub进行开源<code>（网页About Me中有公众号、Github等信息）</code></strong></p>]]></content>
    
    
    <categories>
      
      <category>RADAR</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RADAR</tag>
      
      <tag>ADAS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ADAS-CIS|安森美AR0821两帧150dB是如何练成的？</title>
    <link href="/2023/07/20/1.%E5%AE%89%E6%A3%AE%E7%BE%8E%E4%B8%80%E5%B8%A7150dB%E6%98%AF%E5%A6%82%E4%BD%95%E7%BB%83%E6%88%90%E7%9A%84/"/>
    <url>/2023/07/20/1.%E5%AE%89%E6%A3%AE%E7%BE%8E%E4%B8%80%E5%B8%A7150dB%E6%98%AF%E5%A6%82%E4%BD%95%E7%BB%83%E6%88%90%E7%9A%84/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>“在上篇文章中，我们根据索尼发表的IEEE论文，介绍了索尼车载CIS的大小Pixel的HDR技术，讲述了其Pixel架构、优势。今天，我们再来介绍安森美在2021年于IEEE发布的AR0821架构的论文，我们将介绍安森美是如何在pixel size为2.1um的情况下，动态范围是如何做到单次曝光110dB，两次曝光达到150dB。”</p><p><img src="/img/1_OnsemiLoficHDR/ar0821.png" alt="AR0821"></p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><p>图像传感器扩展动态范围最常见技术是多重曝光方法，将具有不同积分时间的图像合成一个HDR图像，但此方法比较容易造成运动模糊，而且LFM无法保证。</p><p>另外在上篇文章中我们介绍了SONY的SubPixel-HDR技术，索尼使用SubPixel-HDR技术，在3帧的合成的情况下，可以在保证LFM的前提下做到110dB。</p><p>虽然，SubPixel架构可以有效地扩展Sensor的动态范围，但是受制于像素间距以及工艺影响，当pixel size越做越小的时候，其‘小pixel’则会越来越难做。</p><p>因此，更优选的方法是在单个像素在积分时间内完成曝光，然后使动态范围最大化，另外在自然光源下，有LFM的工况下，110 dB几乎涵盖了所有的ADAS使用情况。因此。我们尽力追求单个Pixel的动态范围在一帧曝光的情况下做到110dB。</p><p>今天，我们继续从安森美发布的IEEE的技术论文出发，来讲解车载Sensor厂商另外一个专注于“技术”的巨头安森美最新的pixel架构技术，论文DOI号可以关注我公众号，然后私信《安森美AR0821论文》获取。</p><h1 id="2-‘扩展电容-DCG-多曝光’-HDR"><a href="#2-‘扩展电容-DCG-多曝光’-HDR" class="headerlink" title="2 ‘扩展电容+DCG+多曝光’ HDR"></a>2 ‘扩展电容+DCG+多曝光’ HDR</h1><h2 id="2-1-Pixel架构"><a href="#2-1-Pixel架构" class="headerlink" title="2.1 Pixel架构"></a>2.1 Pixel架构</h2><p>Onsemi论文中给出的AR0821的Pixel架构如下所示：</p><p><img src="/img/1_OnsemiLoficHDR/pixel_arch.png" alt="像素架构"></p><p>上图呈现的像素组合为DCG+overflow电容器，单次曝光可以输出三帧图像，这三张图像分别为：</p><ul><li><p>HCG(DCG and CAP CLOSED)</p></li><li><p>MCG(DCG ON and CAP CLOSED)</p></li><li><p>LCG(DCG and CAP ON)</p></li></ul><p>其中，高密度MiM电容器相对上一代的低增益平面MiM电容器可用性增加。尽管像素间距减小，但FWC(满井容量)增加了近4倍，达到600 ke-。满井的增加最直接的结果就是单次曝光DR相对之前增加14 dB，同时增加低增益电容降低了低增益读取时的读取噪声。</p><h2 id="2-2-Pixel工作时序"><a href="#2-2-Pixel工作时序" class="headerlink" title="2.2 Pixel工作时序"></a>2.2 Pixel工作时序</h2><p>图像曝光、采样时序如下图所示：</p><p><img src="/img/1_OnsemiLoficHDR/timing.png" alt="工作时序"></p><p>可以看出当Sensor工作模式为全HDR合成时，整体曝光分为T1(长曝光)+T2(短曝光)。</p><p>在T1周期内分为三帧进行采样，HCG+MCG+LCG，动态范围可以达到110dB，信号位宽为20bit。</p><p>在T2周期内，使用LCG模式进行依次短曝光，T1&#x2F;T2的曝光比为100，换算成bit为6.64bit，传感器的输出bit从20bit到26bit，动态范围由110dB扩展到了150dB。</p><p>论文中给出sensor的关键指标如下所示：</p><p><img src="/img/1_OnsemiLoficHDR/params.png" alt="sensor参数"></p><p>可以看出，单帧模式下sensor最快帧率可以达到110dB@60fps。加入T2之后sensor帧率有所下降，可以达到150dB@45fps。</p><p>sensor的实拍图如下所示，场景仿真图中给出了ADAS场景中的几个关键场景，如太阳、红绿灯、交通指示灯等场景，可以看出sensor具有较好的动态范围以及LED闪烁抑制功能。</p><p><img src="/img/1_OnsemiLoficHDR/sim.png" alt="仿真场景"></p><h2 id="2-3-Pixel性能对比"><a href="#2-3-Pixel性能对比" class="headerlink" title="2.3 Pixel性能对比"></a>2.3 Pixel性能对比</h2><p>论文最后，Onsemi还给出了sensor的SNR曲线以及当前工作和索尼IMX490的关键指标的对比。SNR曲线如下所示：</p><p><img src="/img/1_OnsemiLoficHDR/snr.png" alt="snr"></p><p>可以看出，Sensor的SNR最大可以做到45dB左右。最大SNR Drop为T1 LCG与T2 LCG交接处，最大可达7dB左右。<br>与IMX490指标对比如下所示：<br><code>(虽然论文没有明说...但只要是做车载相机的应该都懂...)</code></p><p><img src="/img/1_OnsemiLoficHDR/compare.png" alt="参数对比"></p><p>当然孰优孰劣，论文参数只能说明一方面。在实际工程中还要考虑镜头、成本以及<code>国家芯片限制政策</code>各方面因素进行综合考虑。</p><p>最后附上一张论文中AR0821的实拍图：</p><p><img src="/img/1_OnsemiLoficHDR/image.png" alt="实拍图"></p><h1 id="3-结束语"><a href="#3-结束语" class="headerlink" title="3 结束语"></a>3 结束语</h1><p>今天我们为大家介绍了安森美在IEEE中发表的AR0821的技术论文，为大家介绍了其HDR的实现原理与技术架构，希望可以给您带来对于传感器的更深的认知，喜欢的同学可以进行朋友圈分享以及文章在看。<br>如果您对自动驾驶感兴趣，可以关注我的公众号（网页关于我中获取），当然有想了解的话题，也可以私信我，我们将对各位看官感兴趣的话题进行技术分享。</p><p>好了今天就到这里，想看原论文的同学可以公众号私信我进行获取。</p><hr><p><strong>如果您对ADAS感兴趣，欢迎关注我的公众号、知乎、CSDN等，同时发表文章中使用源码会在我的GitHub进行开源<code>（网页About Me中有公众号、Github等信息）</code></strong></p>]]></content>
    
    
    <categories>
      
      <category>CMOS SENSOR</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CMOS SENSOR</tag>
      
      <tag>ONSEMI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ADAS-CIS|一文看懂索尼CIS传感器SubPixel-HDR技术</title>
    <link href="/2023/07/19/0.%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82%E8%BD%A6%E8%BD%BDSONY%E5%A4%A7%E5%B0%8FPixel%E6%8A%80%E6%9C%AF/"/>
    <url>/2023/07/19/0.%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82%E8%BD%A6%E8%BD%BDSONY%E5%A4%A7%E5%B0%8FPixel%E6%8A%80%E6%9C%AF/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>“由于自动驾驶场景需要，一般ADAS系统对于车载CIS(CMOS Image Sensor)传感器的HDR性能以及LFM功能有一定的要求。随着技术的发展，目前市面上的大部分车载相机的动态范围在可以达到≥120dB的同时还支持LFM功能。今天，我们将以Sony大小Pixel的IEEE论文作为切入点，为大家介绍大小像素技术是如何实现的高动态以及LFM功能。感兴趣的同学关注我公众号后台私信我《Sony大小pixel》进行论文pdf版本获取。”</p><p><img src="/img/0_SonySubpixelHDR/subpixel.png" alt="Sony Sensor"></p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><p>实时传感器的发展创造了新的商业和社会变革，特别是互联网物联网和汽车领域。在汽车ADAS应用的众多传感器中，图像传感器是这些领域实现关键功能最重要的传感器，对移动物体、路况检测以及所有光照条件下的物体检测、识别等有着重要的作用。</p><p>图像传感器中HDR是一项重要的性能指标，它代表了同一张图像中可以看到场景中最亮以及最暗场景亮度的比值。例如，即使在黑暗里，必须要通过高灵敏度和低噪声采样识别图像。而在亮处，必须要通过低灵敏度和低噪声进行采样。在之前公众号文章中我们介绍了HDR实现的方式：HDR目前实现方式主要有多曝光合成、DCG以及SubPixel技术等。</p><p>其中，使用多重曝光方法传统的高动态范围技术，由于不同帧是在不同的采样时间进行采集，因此很容易造成运动伪影，这会导致后端算法识别错误。</p><p><img src="/img/0_SonySubpixelHDR/dol.png" alt="DOL HDR"></p><p>另外，在ADAS应用中，交通指示灯识别也是一项重要的任务。发光LED二极管的信号灯由于是PWM驱动，因此实际上它们在工作状态中是不停的眨眼睛。</p><p><img src="/img/0_SonySubpixelHDR/tra_red_light.png" alt="交通灯"></p><p>然而，它们必须看起来像是图像中始终亮起。当使用扩展的方法时仅仅为了捕捉这种闪烁的曝光时间信号，信号在短时间内饱和从而丢失它们的亮度和颜色信息。作为LED闪烁抑制（LFM）方法，采样倍数在曝光期间时间方向上的次数已提出，但此方法有一个非补充期并且不能完全减轻光闪烁效应。</p><p>今天我们将介绍Sony开发的一种新的图像传感器来解决上述这些问题，此传感器的特点是采用亚像素架构设计光电二极管、单个小型光电二极管和像素内浮动电容器，即SubPixel+DCG技术。</p><h1 id="2-SubPixel架构介绍"><a href="#2-SubPixel架构介绍" class="headerlink" title="2 SubPixel架构介绍"></a>2 SubPixel架构介绍</h1><p>图像传感器主要由像素的像素阵列、读出电路(负载MOS晶体管、列ADC、DAC)、驱动器电路(行驱动器、行解码器)、图像信号处理器和其他电路(PLL、稳压器、MIPI I&#x2F;F、CPU等)组成，其整体框图如下图所示：</p><p><img src="/img/0_SonySubpixelHDR/sensor_arch.png" alt="Sensor Arch"></p><p>其中，相对于其他Sensor，最大的不同即为像素架构，其微观显微镜的像素俯视图如下图(a)所示。一个像素具有大片上微透镜（OCL）和小的OCL，分别给SP1和SP2使用。SP2的OCL位于SP1的OCL的间隙部分中，这使得SP1与SP2的灵敏度比等于10:1。</p><p><img src="/img/0_SonySubpixelHDR/imx390_pixel.png" alt="Pixel Arch"></p><p>上图右侧显示了子像素的电路架构示意图，该电路架构由单个大的光电二极管(SP1)，单个小光电二极管(SP2)，像素内浮动电容器(FC)和七个晶体管组成。</p><p>其中:</p><ul><li><p>SP1具有高灵敏度(绿色)36000e-&#x2F;lx࣭s，而SP2的灵敏度为SP1的1&#x2F;10。由于FC的存在，SP1的线性全井容量(FWC)为10000e-，SP2的FWC为78500e-。</p></li><li><p>电路的中七个晶体管为：SP1的传输栅极(TGL)，SP2的传输栅极(TGS)，浮动扩散栅极(FDG)、浮动电容器栅极(FCG)、复位晶体管(RST)、选择晶体管(SEL)和源极跟随器放大器(AMP)。</p></li><li><p>浮动扩散（FD），FD在此架构中被分离为FD1、FD2和FD3，其中FD3是由FDG和FCG组成。FDG以及DCG被用作切换，以分别用于连接FD1与FD2、FD2与FD3。FC的两个电极连接到FD3以及其供电电压FCVDD。</p></li></ul><p>下图显示了相应的像素截面上图(a)中的虚线，深沟在硅底处采用隔离的方式来防止从SP1到SP2的电荷泄漏。</p><p><img src="/img/0_SonySubpixelHDR/pixel_arch.png" alt="Pixel Arch"></p><h1 id="3-SubPixel-HDR合成-LFM实现"><a href="#3-SubPixel-HDR合成-LFM实现" class="headerlink" title="3 SubPixel HDR合成&amp;LFM实现"></a>3 SubPixel HDR合成&amp;LFM实现</h1><p>相对于多帧曝光HDR传感器，SubPixel架构的传感器中SP1和SP2的信号被同一时刻采样并且被串行输出。同时，SP1以及SP2中累积的电荷都会被转换为两种模式下的电压，即高转换增益（HCG）以及通过切换FDG来实现的低转换增益（LCG）。因此，SubPixel传感器可以输出同一时刻采集的4张不同灵敏度的图像，完美地解决运动模糊的问题，如下图所示：</p><p><img src="/img/0_SonySubpixelHDR/hdr_merge.png" alt="四帧HDR"></p><p>通过四帧图像合成，可以轻松地输出24bit的HDR图像，如下图所示：</p><p><img src="/img/0_SonySubpixelHDR/hdr_linear.png" alt="Alt text"></p><p>同时，由于在HDR合成后，在曝光在10ms的情况下，单帧动态范围便可以实现大于120dB的效果。因此，在国内交通LED灯为100Hz频率的情况下，我们将曝光控制在10ms便可以采集到整个LED的能量周期，如下图所示：</p><p><img src="/img/0_SonySubpixelHDR/lfm.png" alt="LFM"></p><p>论文中给出了Sensor在曝光为11ms的情况下，SP1H+SP1L+SPL三帧合成的仿真效果如下：</p><p><img src="/img/0_SonySubpixelHDR/paper.png" alt="仿真效果"></p><p>可以看出，在隧道场景下，隧道口明亮处、隧道内暗部以及LED灯信息都得以保留，相对于传统多帧合成Sensor有了很大的提升。最后，论文也给出了Sensor内部的工作时序图，如下所示：</p><p><img src="/img/0_SonySubpixelHDR/timeing.png" alt="时序图"></p><p>可以看出，相对于普通Sensor，SubPixel架构的整体工作流程也分为主要的三步：复位、曝光、读出，只是在细节处有差异，同时多了一个SP2小像素的处理。</p><h1 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h1><p>传感器技术的发展日新月异，为自动驾驶提供了良好的数据采集源，也带来了一系列的产业变革。然而，在每个新技术应用的背后都有着无数工程师的奇思妙想以及夜以继日的努力与实验。我们在欣赏与运用技术的同时，更要尊重知识产权，饮水思源，尊重前人做的努力与付出。最后，我们也更希望诸位可以站在巨人的肩膀上，看的更高、走的更远。</p><p>今天我们为大家介绍了Sony在IEEE中发表的大小像素的技术论文，为大家介绍了大小像素的实现原理与技术架构，希望可以给您带来对于传感器的更深的认知，喜欢的同学可以进行朋友圈分享以及文章在看。</p><p>如果您对自动驾驶感兴趣，可以关注本公众号，当然有想了解的话题，也可以私信我，我们将对各位看官感兴趣的话题进行技术分享。</p><p>好了今天就到这里，想看原论文的同学可以关注我公众号并私信回复《Sony大小pixel》获取论文。&#96;</p><hr><p><strong>如果您对ADAS感兴趣，欢迎关注我的公众号、知乎、CSDN等，同时发表文章中使用源码会在我的GitHub进行开源<code>（网页About Me中有公众号、Github等信息）</code></strong></p>]]></content>
    
    
    <categories>
      
      <category>CMOS SENSOR</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CMOS SENSOR</tag>
      
      <tag>SONY</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
